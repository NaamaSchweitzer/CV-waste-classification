{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPZPCHPgdTpBGY+/rwZJvkt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaamaSchweitzer/CV-waste-classification/blob/ModelProcessing/YoloV8n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6R-jtxnnNUe",
        "outputId": "d09962aa-c333-4f5c-8b26-e1c7885f8c25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-29 12:45:05--  https://raw.githubusercontent.com/NaamaSchweitzer/CV-waste-classification/Preprocessing/CV_Waste_Classification.ipynb\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 116592 (114K) [text/plain]\n",
            "Saving to: â€˜CV_Waste_Classification.ipynbâ€™\n",
            "\n",
            "\r          CV_Waste_   0%[                    ]       0  --.-KB/s               \rCV_Waste_Classifica 100%[===================>] 113.86K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-11-29 12:45:05 (10.9 MB/s) - â€˜CV_Waste_Classification.ipynbâ€™ saved [116592/116592]\n",
            "\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Kaggle authentication setup complete.\n",
            "Dataset URL: https://www.kaggle.com/datasets/alyyan/trash-detection\n",
            "License(s): MIT\n",
            "Downloading trash-detection.zip to /content\n",
            "100% 1.23G/1.23G [00:16<00:00, 79.1MB/s]\n",
            "100% 1.23G/1.23G [00:16<00:00, 82.0MB/s]\n",
            "CV_Waste_Classification.ipynb  sample_data  trash-detection.zip\n",
            "Dataset\n",
            "Dataset downloaded and extracted successfully!\n",
            "data.yaml  images/  labels/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (6.0.3)\n",
            "PyYAML installed successfully.\n",
            "Dataset metadata loaded from: trash-detection/Dataset/data.yaml\n",
            "Detected classes (nc): 4\n",
            "Class names: ['dirt', 'liquid', 'marks', 'trash']\n",
            "Processing 1229 label files...\n",
            "\n",
            "--- Dataset Class Analysis ---\n",
            "Total instances (bounding boxes detected): 7900\n",
            "Class distribution:\n",
            "  - dirt (ID 0): 1418 instances\n",
            "  - liquid (ID 1): 494 instances\n",
            "  - marks (ID 2): 3373 instances\n",
            "  - trash (ID 3): 2615 instances\n",
            "Processing 308 label files...\n",
            "\n",
            "--- Dataset Class Analysis ---\n",
            "Total instances (bounding boxes detected): 2018\n",
            "Class distribution:\n",
            "  - dirt (ID 0): 367 instances\n",
            "  - liquid (ID 1): 140 instances\n",
            "  - marks (ID 2): 822 instances\n",
            "  - trash (ID 3): 689 instances\n",
            "Total instances in training set: 7900\n",
            "Number of classes: 4\n",
            "Average instance count per class: 1975.00\n",
            "Identified minority classes for augmentation: ['dirt', 'liquid']\n",
            "Created directory: ./trash-detection/Dataset/images/augmented_train\n",
            "Created directory: ./trash-detection/Dataset/labels/augmented_train\n",
            "Necessary libraries imported: os, numpy, PIL (Image, ImageEnhance), random.\n",
            "Utility functions 'read_yolo_labels' and 'write_yolo_labels' defined.\n",
            "Data augmentation functions (horizontal_flip, vertical_flip, rotate_90_clockwise, adjust_brightness) defined.\n",
            "Starting data augmentation for minority classes: ['dirt', 'liquid']\n",
            "Original images directory: ./trash-detection/Dataset/images/train\n",
            "Original labels directory: ./trash-detection/Dataset/labels/train\n",
            "Augmented images directory: ./trash-detection/Dataset/images/augmented_train\n",
            "Augmented labels directory: ./trash-detection/Dataset/labels/augmented_train\n",
            "Finished data augmentation. Total augmented images/labels generated: 1653\n",
            "Augmented data stored in: ./trash-detection/Dataset/images/augmented_train and ./trash-detection/Dataset/labels/augmented_train\n",
            "Processing augmented labels from: ./trash-detection/Dataset/labels/augmented_train\n",
            "Found 1653 augmented label files.\n",
            "\n",
            "Total instances added from augmented data: 14193\n",
            "\n",
            "--- Combined Dataset Class Analysis (Original + Augmented) ---\n",
            "Total instances (bounding boxes detected) in combined dataset: 22093\n",
            "Combined Class distribution:\n",
            "  - dirt (ID 0): 5672 instances\n",
            "  - liquid (ID 1): 1976 instances\n",
            "  - marks (ID 2): 11830 instances\n",
            "  - trash (ID 3): 2615 instances\n",
            "\n",
            "--- Class Balance Improvement Summary ---\n",
            "Original training class distribution:\n",
            "  - dirt (ID 0): 1418 instances\n",
            "  - liquid (ID 1): 494 instances\n",
            "  - marks (ID 2): 3373 instances\n",
            "  - trash (ID 3): 2615 instances\n",
            "\n",
            "Average instance count per class in original training set: 1975.00\n",
            "Average instance count per class in combined dataset: 5523.25\n",
            "Classes still below the new average: ['liquid', 'trash']\n",
            "Further augmentation might be beneficial for these classes.\n",
            "Starting data augmentation for minority classes: ['dirt', 'liquid']\n",
            "Original images directory: ./trash-detection/Dataset/images/train\n",
            "Original labels directory: ./trash-detection/Dataset/labels/train\n",
            "Augmented images directory: ./trash-detection/Dataset/images/augmented_train\n",
            "Augmented labels directory: ./trash-detection/Dataset/labels/augmented_train\n",
            "Finished data augmentation. Total augmented images/labels generated: 1653\n",
            "Augmented data stored in: ./trash-detection/Dataset/images/augmented_train and ./trash-detection/Dataset/labels/augmented_train\n",
            "Processing augmented labels from: ./trash-detection/Dataset/labels/augmented_train\n",
            "Found 1653 augmented label files.\n",
            "\n",
            "Total instances added from augmented data: 5736\n",
            "\n",
            "--- Combined Dataset Class Analysis (Original + Augmented) ---\n",
            "Total instances (bounding boxes detected) in combined dataset: 13636\n",
            "Combined Class distribution:\n",
            "  - dirt (ID 0): 5672 instances\n",
            "  - liquid (ID 1): 1976 instances\n",
            "  - marks (ID 2): 3373 instances\n",
            "  - trash (ID 3): 2615 instances\n",
            "\n",
            "--- Class Balance Improvement Summary ---\n",
            "Original training class distribution:\n",
            "  - dirt (ID 0): 1418 instances\n",
            "  - liquid (ID 1): 494 instances\n",
            "  - marks (ID 2): 3373 instances\n",
            "  - trash (ID 3): 2615 instances\n",
            "\n",
            "Average instance count per class in original training set: 1975.00\n",
            "Average instance count per class in combined dataset: 3409.00\n",
            "Classes still below the new average: ['liquid', 'marks', 'trash']\n",
            "Further augmentation might be beneficial for these classes.\n",
            "Found 308 potential image files in ./trash-detection/Dataset/images/val\n",
            "\n",
            "Total image-label pairs found for validation: 308\n",
            "\n",
            "Examples of image-label mapping:\n",
            "  Image: ./trash-detection/Dataset/images/val/782.jpg\n",
            "  Label: ./trash-detection/Dataset/labels/val/782.txt\n",
            "  Image: ./trash-detection/Dataset/images/val/683.jpg\n",
            "  Label: ./trash-detection/Dataset/labels/val/683.txt\n",
            "  Image: ./trash-detection/Dataset/images/val/batch10_000035.jpg\n",
            "  Label: ./trash-detection/Dataset/labels/val/batch10_000035.txt\n",
            "  Image: ./trash-detection/Dataset/images/val/731.jpg\n",
            "  Label: ./trash-detection/Dataset/labels/val/731.txt\n",
            "  Image: ./trash-detection/Dataset/images/val/912.jpg\n",
            "  Label: ./trash-detection/Dataset/labels/val/912.txt\n",
            "Imported train_test_split from sklearn.model_selection.\n",
            "Total original validation items: 308\n",
            "Number of items in the new validation set (30%): 92\n",
            "Number of items in the new test set (70%): 216\n",
            "Created directory: ./trash-detection/Dataset/images/test\n",
            "Created directory: ./trash-detection/Dataset/labels/test\n",
            "Created directory: ./trash-detection/Dataset/images/new_val\n",
            "Created directory: ./trash-detection/Dataset/labels/new_val\n",
            "\n",
            "Moving files to test directories: ./trash-detection/Dataset/images/test and ./trash-detection/Dataset/labels/test\n",
            "Moving files to new validation directories: ./trash-detection/Dataset/images/new_val and ./trash-detection/Dataset/labels/new_val\n",
            "\n",
            "File moving complete!\n",
            "  - Total images moved to test directory: 216\n",
            "  - Total labels moved to test directory: 216\n",
            "  - Total images moved to new validation directory: 92\n",
            "  - Total labels moved to new validation directory: 92\n",
            "Number of images in the new test set directory (./trash-detection/Dataset/images/test): 216\n",
            "Number of images in the new validation set directory (./trash-detection/Dataset/images/new_val): 92\n",
            "Expected test images: 216\n",
            "Expected new validation images: 92\n",
            "File counts match the expected split proportions.\n",
            "Successfully updated trash-detection/Dataset/data.yaml.\n",
            "\n",
            "New data.yaml content:\n",
            "names:\n",
            "- dirt\n",
            "- liquid\n",
            "- marks\n",
            "- trash\n",
            "nc: 4\n",
            "test: images/test\n",
            "train: images/train\n",
            "val: images/new_val\n",
            "\n",
            "\n",
            "--- Dataset Statistics ---\n",
            "\n",
            "Train Set:\n",
            "  Images: 2882\n",
            "  Labels: 2882\n",
            "  Instances (bounding boxes): 13636\n",
            "\n",
            "New val Set:\n",
            "  Images: 92\n",
            "  Labels: 92\n",
            "  Instances (bounding boxes): 591\n",
            "\n",
            "Test Set:\n",
            "  Images: 216\n",
            "  Labels: 216\n",
            "  Instances (bounding boxes): 1427\n"
          ]
        }
      ],
      "source": [
        "!wget -O CV_Waste_Classification.ipynb \\\n",
        "  https://raw.githubusercontent.com/NaamaSchweitzer/CV-waste-classification/Preprocessing/CV_Waste_Classification.ipynb\n",
        "\n",
        "%run CV_Waste_Classification.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YOLOv8 (Ultralytics)\n"
      ],
      "metadata": {
        "id": "N5HdvYsInnc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "# ===== IMPORTANT: RUN THIS CELL FIRST =====\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Set the CORRECT path to data.yaml\n",
        "data_config_path = './trash-detection/Dataset/data.yaml'\n",
        "\n",
        "# Verify it exists\n",
        "if os.path.exists(data_config_path):\n",
        "    print(f\"âœ“ Data configuration found at {data_config_path}\")\n",
        "else:\n",
        "    print(f\"âœ— Error: data.yaml not found at {data_config_path}\")\n",
        "\n",
        "# Set model name\n",
        "model_name = 'yolov8n.pt'\n",
        "\n",
        "# Helper function\n",
        "def load_pretrained_model(name):\n",
        "    return YOLO(name)\n",
        "\n",
        "print(f\"âœ“ Model name set to: {model_name}\")\n",
        "print(f\"âœ“ data_config_path = {data_config_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnCzOmvvnrGM",
        "outputId": "df52c68d-cc99-44dd-ede4-9738cd3ff189"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.233-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.233-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.233 ultralytics-thop-2.0.18\n",
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "âœ“ Data configuration found at ./trash-detection/Dataset/data.yaml\n",
            "âœ“ Model name set to: yolov8n.pt\n",
            "âœ“ data_config_path = ./trash-detection/Dataset/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation and Environment Setup\n",
        "Before we begin, we need to install the ultralytics library. This library provides all the tools needed for training, evaluating, and using YOLOv8 models. The following cell installs the library, imports the required modules, and checks the environment (including GPU detection)."
      ],
      "metadata": {
        "id": "ibT_OWwmpYSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, Image\n",
        "\n",
        "ultralytics.checks()\n",
        "\n",
        "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"Warning: GPU not detected. Training might be slow.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxGmJnhPo_xB",
        "outputId": "1effe554-f256-45bb-b9a6-f8ecbe194a43"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 40.9/112.6 GB disk)\n",
            "\n",
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Selecting a Base Model (Pretrained Backbone)\n",
        "Model Selection and Transfer Learning\n",
        "I chose the YOLOv8n (Nano version) model as our pretrained backbone. This is a lightweight and efficient model pre-trained on the large COCO dataset. Loading these weights gives us a strong foundation for Transfer Learning. We also verify that the path to the data.yaml file is correct."
      ],
      "metadata": {
        "id": "0NTgITNOqDvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yaml\n",
        "import kagglehub\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Step 1: Download dataset\n",
        "print(\"Downloading dataset...\")\n",
        "path = \"./trash-detection\"\n",
        "dataset_root = f\"{path}/Dataset\"\n",
        "print(f\"Dataset root: {dataset_root}\")\n",
        "\n",
        "# Step 2: Read and fix data.yaml\n",
        "original_yaml_path = f\"{dataset_root}/data.yaml\"\n",
        "print(f\"\\nOriginal data.yaml contents:\")\n",
        "with open(original_yaml_path, 'r') as f:\n",
        "    content = f.read()\n",
        "    print(content)\n",
        "\n",
        "# Step 4: Verify images exist\n",
        "train_path = f\"{dataset_root}/images/augmented_train\"\n",
        "val_path = f\"{dataset_root}/images/new_val\"\n",
        "test_path = f\"{dataset_root}/images/test\"\n",
        "print(f\"\\nVerifying paths:\")\n",
        "print(f\"  Train images exist: {os.path.exists(train_path)} ({len(os.listdir(train_path)) if os.path.exists(train_path) else 0} files)\")\n",
        "print(f\"  Val images exist: {os.path.exists(val_path)} ({len(os.listdir(val_path)) if os.path.exists(val_path) else 0} files)\")\n",
        "print(f\"  Train images exist: {os.path.exists(test_path)} ({len(os.listdir(test_path)) if os.path.exists(test_path) else 0} files)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwT-5I8YqFPY",
        "outputId": "6ecb343e-ae3c-401a-df1b-64d3115db561"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n",
            "Dataset root: ./trash-detection/Dataset\n",
            "\n",
            "Original data.yaml contents:\n",
            "names:\n",
            "- dirt\n",
            "- liquid\n",
            "- marks\n",
            "- trash\n",
            "nc: 4\n",
            "test: images/test\n",
            "train: images/augmented_train\n",
            "val: images/new_val\n",
            "\n",
            "\n",
            "Verifying paths:\n",
            "  Train images exist: True (1653 files)\n",
            "  Val images exist: True (92 files)\n",
            "  Train images exist: True (216 files)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training - First Run (Fine-Tuning Run 1)\n",
        "Now we'll start the Fine-Tuning process. I decided to train for 30 epochs. In this run, we'll use the standard YOLOv8 parameters (including the default initial learning rate lr0 of 0.01). The results will be saved in a dedicated folder (YOLOv8n_Run1_DefaultLR) for comparison later. We use batch=-1 to allow the library to choose the optimal batch size for the available GPU memory"
      ],
      "metadata": {
        "id": "qwXAWY7Sq7Ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Train with corrected data.yaml\n",
        "EPOCHS = 30\n",
        "IMAGE_SIZE = 640\n",
        "PROJECT_NAME = 'runs/detect'\n",
        "RUN1_NAME = 'YOLOv8n_Run1_DefaultLR'\n",
        "\n",
        "print(f\"\\nStarting Training Run 1 ({RUN1_NAME}) for {EPOCHS} epochs...\")\n",
        "print(f\"Using data config: {original_yaml_path}\")\n",
        "\n",
        "yoloV8N = YOLO('yolov8n.pt')\n",
        "\n",
        "results_run1 = yoloV8N.train(\n",
        "    data=original_yaml_path,  # Use the corrected file\n",
        "    epochs=EPOCHS,\n",
        "    imgsz=IMAGE_SIZE,\n",
        "    patience=10,\n",
        "    batch=-1,\n",
        "    project=PROJECT_NAME,\n",
        "    name=RUN1_NAME\n",
        ")\n",
        "print(\"Training Run 1 finished successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1uoZfwOq9Oi",
        "outputId": "60ca3eb0-1690-4182-f679-be68a498c3eb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Training Run 1 (YOLOv8n_Run1_DefaultLR) for 30 epochs...\n",
            "Using data config: ./trash-detection/Dataset/data.yaml\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.2MB 121.4MB/s 0.1s\n",
            "Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=./trash-detection/Dataset/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=YOLOv8n_Run1_DefaultLR, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/YOLOv8n_Run1_DefaultLR, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 25.2MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,628 parameters, 3,011,612 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 103.1MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1530.9Â±523.4 MB/s, size: 50.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/trash-detection/Dataset/labels/augmented_train... 1653 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1653/1653 2.4Kit/s 0.7s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/trash-detection/Dataset/labels/augmented_train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.74G total, 0.10G reserved, 0.06G allocated, 14.58G free\n",
            "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
            "     3011628       8.197         0.382         79.21         599.5        (1, 3, 640, 640)                    list\n",
            "     3011628       16.39         0.526         19.59         182.9        (2, 3, 640, 640)                    list\n",
            "     3011628       32.79         0.830         20.37         156.4        (4, 3, 640, 640)                    list\n",
            "     3011628       65.58         1.420         31.66         155.8        (8, 3, 640, 640)                    list\n",
            "     3011628       131.2         2.494         58.63         165.8       (16, 3, 640, 640)                    list\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 62 for CUDA:0 9.16G/14.74G (62%) âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1424.6Â±666.0 MB/s, size: 31.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/trash-detection/Dataset/labels/augmented_train.cache... 1653 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1653/1653 3.2Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1202.3Â±1413.0 MB/s, size: 760.8 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/trash-detection/Dataset/labels/new_val... 92 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 92/92 1.6Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/trash-detection/Dataset/labels/new_val.cache\n",
            "Plotting labels to /content/runs/detect/YOLOv8n_Run1_DefaultLR/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.000484375), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/YOLOv8n_Run1_DefaultLR\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/30      7.48G      1.762      3.441      1.114        239        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.2s/it 32.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.5s/it 5.5s\n",
            "                   all         92        591    0.00404      0.206     0.0553     0.0298\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/30         7G      1.567      1.627      1.045        243        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.3it/s 21.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.5s/it 1.5s\n",
            "                   all         92        591    0.00297      0.249      0.127     0.0705\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/30      7.02G      1.481      1.342      1.023        214        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.0it/s 26.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1it/s 0.9s\n",
            "                   all         92        591      0.945      0.101       0.22      0.141\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/30      7.04G      1.442      1.202      1.018        208        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.0it/s 26.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0it/s 1.0s\n",
            "                   all         92        591      0.707      0.287      0.251      0.149\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/30      7.05G      1.446      1.087      1.013        222        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.0s/it 27.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0s/it 1.0s\n",
            "                   all         92        591      0.727      0.272       0.23      0.138\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/30      7.07G      1.415      1.005      1.008        203        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.0it/s 26.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0it/s 1.0s\n",
            "                   all         92        591      0.487      0.286      0.227       0.14\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/30      7.09G      1.387       0.92     0.9943        245        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.0it/s 26.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.4s/it 1.4s\n",
            "                   all         92        591      0.292      0.313      0.264      0.177\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/30      7.11G      1.337     0.8609      0.984        241        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.0it/s 26.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0s/it 1.0s\n",
            "                   all         92        591      0.539      0.337      0.315      0.198\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/30      7.12G      1.325      0.826     0.9747        224        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.0it/s 26.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0s/it 1.0s\n",
            "                   all         92        591      0.248      0.316      0.269      0.164\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/30      7.14G      1.323     0.8105     0.9775        219        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.0s/it 27.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1it/s 0.9s\n",
            "                   all         92        591      0.576      0.334       0.31      0.191\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/30      7.16G       1.29      0.764     0.9638        201        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.0it/s 26.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.2it/s 0.8s\n",
            "                   all         92        591      0.308      0.315      0.337      0.221\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/30      7.17G       1.27     0.7593     0.9597        218        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.0it/s 26.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.2s/it 1.2s\n",
            "                   all         92        591      0.264      0.336      0.289      0.182\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/30      7.19G      1.256     0.7382     0.9602        219        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.0s/it 27.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.2it/s 0.8s\n",
            "                   all         92        591      0.264      0.336      0.277      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/30      7.21G      1.243     0.7109     0.9466        221        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.0it/s 26.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0s/it 1.0s\n",
            "                   all         92        591       0.27      0.317      0.273      0.183\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/30      7.22G       1.22     0.6896     0.9447        199        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.0it/s 26.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0it/s 1.0s\n",
            "                   all         92        591      0.283      0.382      0.321      0.216\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/30      7.24G      1.191     0.6846     0.9402        229        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.0it/s 26.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0it/s 1.0s\n",
            "                   all         92        591      0.278      0.328      0.307       0.22\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/30      7.26G      1.201     0.6765     0.9398        196        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.0s/it 27.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.2s/it 1.2s\n",
            "                   all         92        591      0.296      0.337      0.334      0.228\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/30      7.28G      1.184     0.6589     0.9363        207        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.0s/it 27.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.2s/it 1.2s\n",
            "                   all         92        591        0.3      0.376      0.314      0.225\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/30      7.29G      1.174     0.6507     0.9353        214        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.0it/s 27.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1it/s 1.0s\n",
            "                   all         92        591      0.311      0.367      0.333      0.241\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/30      7.31G      1.153     0.6299     0.9241        240        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.0it/s 26.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.2s/it 1.2s\n",
            "                   all         92        591      0.308      0.369      0.335      0.236\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/30      7.33G      1.119      0.615     0.9182        136        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.0s/it 27.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.3s/it 1.3s\n",
            "                   all         92        591      0.288      0.352      0.331      0.236\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/30      7.35G      1.103     0.5951     0.9153        134        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.1it/s 25.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.2it/s 0.9s\n",
            "                   all         92        591      0.337      0.344      0.334      0.237\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/30      7.36G      1.106     0.5797     0.9147        129        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.1it/s 25.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.3it/s 0.8s\n",
            "                   all         92        591      0.331      0.384      0.358      0.256\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/30      7.38G      1.073     0.5663     0.9094        145        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.1it/s 25.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1s/it 1.1s\n",
            "                   all         92        591      0.289       0.37      0.348      0.246\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/30      7.16G      1.052     0.5552     0.9038        140        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.1it/s 24.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0it/s 1.0s\n",
            "                   all         92        591      0.308      0.382      0.357      0.259\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/30      7.16G      1.044     0.5435     0.8984        147        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.1it/s 25.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.2it/s 0.8s\n",
            "                   all         92        591      0.279       0.37      0.326      0.235\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/30      7.16G      1.033     0.5314     0.8986        127        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.1it/s 25.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0s/it 1.0s\n",
            "                   all         92        591      0.335      0.375      0.366       0.26\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/30      7.16G      1.022     0.5248     0.8921        131        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.1it/s 25.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0s/it 1.0s\n",
            "                   all         92        591      0.309      0.384      0.345      0.252\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/30      7.16G      1.006     0.5196     0.8869        136        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.1it/s 24.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.4s/it 1.4s\n",
            "                   all         92        591      0.295      0.386      0.341      0.251\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/30      7.16G     0.9843     0.5023     0.8805        136        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 27/27 1.1it/s 24.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.3s/it 1.3s\n",
            "                   all         92        591      0.302      0.383      0.357       0.26\n",
            "\n",
            "30 epochs completed in 0.239 hours.\n",
            "Optimizer stripped from /content/runs/detect/YOLOv8n_Run1_DefaultLR/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs/detect/YOLOv8n_Run1_DefaultLR/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs/detect/YOLOv8n_Run1_DefaultLR/weights/best.pt...\n",
            "Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.2s/it 1.2s\n",
            "                   all         92        591      0.335      0.373      0.366       0.26\n",
            "                  dirt         29         99      0.544      0.778      0.635      0.436\n",
            "                liquid         11         42      0.796      0.714      0.827      0.603\n",
            "                 marks         31        239          0          0          0          0\n",
            "                 trash         44        211          0          0          0          0\n",
            "Speed: 0.2ms preprocess, 2.7ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/YOLOv8n_Run1_DefaultLR\u001b[0m\n",
            "Training Run 1 finished successfully.\n"
          ]
        }
      ]
    }
  ]
}