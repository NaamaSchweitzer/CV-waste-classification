{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7J52Svlh7jFyfiqQG8Hv2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaamaSchweitzer/CV-waste-classification/blob/Preprocessing/CV_Waste_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIYrGJvA9NAQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faf82129"
      },
      "source": [
        "### Kaggle Setup and Dataset Download\n",
        "\n",
        "This section will guide you through setting up Kaggle in your Colab environment and downloading the `alyyan/trash-detection` dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8741cb1c",
        "outputId": "3f1094c2-b62e-4037-80fb-fdd02795d4a0"
      },
      "source": [
        "import os\n",
        "\n",
        "# Install the Kaggle API client\n",
        "!pip install kaggle\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "062a03be"
      },
      "source": [
        "#### Authenticate with Kaggle\n",
        "\n",
        "To download datasets from Kaggle, you need to authenticate using your Kaggle API token. Follow these steps:\n",
        "\n",
        "1.  Go to your Kaggle account page (https://www.kaggle.com/your-username/account).\n",
        "2.  Scroll down to the 'API' section and click 'Create New API Token'. This will download a `kaggle.json` file.\n",
        "3.  In Colab, click on the ðŸ”‘ icon (Secrets) in the left sidebar. Add a new secret named `KAGGLE_USERNAME` for your Kaggle username and `KAGGLE_KEY` for your Kaggle API key (from the `kaggle.json` file).\n",
        "\n",
        "Alternatively, you can upload the `kaggle.json` file directly:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc06a608",
        "outputId": "acf2d219-bd96-4d07-c7ca-589536faa0ff"
      },
      "source": [
        "# Option 1: Using Colab Secrets (Recommended)\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Ensure these secrets are set in Colab's Secrets manager\n",
        "os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME')\n",
        "os.environ['KAGGLE_KEY'] = userdata.get('KAGGLE_KEY')\n",
        "\n",
        "# Option 2: Uploading kaggle.json directly (uncomment and run if not using secrets)\n",
        "# from google.colab import files\n",
        "# files.upload() # This will prompt you to upload the kaggle.json file\n",
        "\n",
        "# Create .kaggle directory if it doesn't exist and move the file\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json # Set permissions\n",
        "\n",
        "print(\"Kaggle authentication setup complete.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Kaggle authentication setup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "048d87df"
      },
      "source": [
        "#### Download the Dataset\n",
        "\n",
        "Now we will download the `trash-detection` dataset from Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "398c42d6",
        "outputId": "f6d1c2d5-6b36-4347-cecd-20dfc6179c9b"
      },
      "source": [
        "# Download the dataset\n",
        "!kaggle datasets download -d alyyan/trash-detection\n",
        "\n",
        "# List the downloaded file(s) to verify\n",
        "!ls\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/alyyan/trash-detection\n",
            "License(s): MIT\n",
            "Downloading trash-detection.zip to /content\n",
            "100% 1.23G/1.23G [00:11<00:00, 211MB/s]\n",
            "100% 1.23G/1.23G [00:11<00:00, 111MB/s]\n",
            "sample_data  trash-detection.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1e130a9"
      },
      "source": [
        "#### Unzip the Dataset\n",
        "\n",
        "The dataset is typically downloaded as a zip file. Let's extract its contents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed8f9c32",
        "outputId": "d6e2a035-66df-48d0-c9e1-14dfdc528c16"
      },
      "source": [
        "# Unzip the dataset (assuming it's a .zip file)\n",
        "!unzip -q trash-detection.zip -d trash-detection\n",
        "\n",
        "# List the contents of the extracted directory\n",
        "!ls trash-detection\n",
        "\n",
        "print(\"Dataset downloaded and extracted successfully!\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset\n",
            "Dataset downloaded and extracted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f610998a"
      },
      "source": [
        "# Task\n",
        "Analyze the structure of the `trash-detection/Dataset` directory, read the `trash-detection/Dataset/data.yaml` file to extract class names, count the total instances and analyze the class balance by processing the label files within the dataset, and finally provide a comprehensive summary of the dataset including its overall size, detected classes, and the distribution of instances across these classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcd81a6e"
      },
      "source": [
        "## Explore Dataset Structure\n",
        "\n",
        "### Subtask:\n",
        "List the contents of the `trash-detection/Dataset` directory to understand how the images and labels are organized.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e3215e6"
      },
      "source": [
        "**Reasoning**:\n",
        "To understand how the images and labels are organized, I will list the contents of the `trash-detection/Dataset` directory using a shell command.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc1b073a",
        "outputId": "b7726b3a-4708-4f98-9940-bbee34e88670"
      },
      "source": [
        "import os\n",
        "\n",
        "# List the contents of the 'trash-detection/Dataset' directory\n",
        "!ls -F trash-detection/Dataset"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.yaml  images/  labels/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5747c5d5"
      },
      "source": [
        "## Read Data Configuration\n",
        "\n",
        "### Subtask:\n",
        "Load and parse the `trash-detection/Dataset/data.yaml` file to extract class names and any other relevant dataset metadata.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f1b6c12"
      },
      "source": [
        "**Reasoning**:\n",
        "Before parsing the YAML file, the `pyyaml` library needs to be installed, as it's not part of the standard Python library and was not installed in previous steps.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e01de6b9",
        "outputId": "578e9029-fef2-4000-b8df-b0735780664f"
      },
      "source": [
        "import os\n",
        "\n",
        "# Install the PyYAML library to parse YAML files\n",
        "!pip install pyyaml\n",
        "\n",
        "print(\"PyYAML installed successfully.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (6.0.3)\n",
            "PyYAML installed successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3d7d217a"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that PyYAML is installed, I will import the `yaml` library, construct the path to `data.yaml`, open and parse it using `yaml.safe_load`, and then extract the class names as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b5c94bd",
        "outputId": "38a6d647-9f03-4ef0-b285-7797a1ac8f39"
      },
      "source": [
        "import yaml\n",
        "\n",
        "# Construct the full path to the data.yaml file\n",
        "data_yaml_path = 'trash-detection/Dataset/data.yaml'\n",
        "\n",
        "# Initialize variables\n",
        "class_names = []\n",
        "\n",
        "# Open and read the data.yaml file\n",
        "with open(data_yaml_path, 'r') as file:\n",
        "    data = yaml.safe_load(file)\n",
        "\n",
        "# Extract class names\n",
        "if 'names' in data:\n",
        "    class_names = data['names']\n",
        "elif 'nc' in data and 'names' in data:\n",
        "    class_names = data['names']\n",
        "\n",
        "print(f\"Dataset metadata loaded from: {data_yaml_path}\")\n",
        "print(f\"Detected classes (nc): {len(class_names)}\")\n",
        "print(f\"Class names: {class_names}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset metadata loaded from: trash-detection/Dataset/data.yaml\n",
            "Detected classes (nc): 4\n",
            "Class names: ['dirt', 'liquid', 'marks', 'trash']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "643d0856"
      },
      "source": [
        "## Count Total Instances and Analyze Class Balance\n",
        "\n",
        "### Subtask:\n",
        "Identify the label files (e.g., .txt files) within the dataset and count the total number of labels. Then, iterate through these label files to count the occurrences of each class, providing a breakdown of the class balance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89444eda"
      },
      "source": [
        "**Reasoning**:\n",
        "I will implement the instructions to identify label files, count total instances, and analyze class balance by iterating through the label directory, reading each label file, extracting class IDs, and then aggregating the counts for each class.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "923a0b54"
      },
      "source": [
        "# Task\n",
        "Count the total number of labels in `trash-detection/Dataset/labels`, and then parse the class ID from each line in these label files (which are in YOLO annotation format) to count the occurrences of each class and analyze the class balance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b93b2709"
      },
      "source": [
        "## Count Total Instances and Analyze Class Balance\n",
        "\n",
        "### Subtask:\n",
        "Identify the label files (e.g., .txt files) within the dataset, which are in YOLO annotation format. Iterate through these label files, parse the class ID from each line (the first element), and count the total number of instances and the occurrences of each class to provide a breakdown of the class balance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a3bafe6"
      },
      "source": [
        "**Reasoning**:\n",
        "To count total instances and analyze class balance, I will define the labels directory, initialize counters, iterate through all .txt label files, extract class IDs from each line, and aggregate the counts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bc2ff07",
        "outputId": "9b45a93c-7e76-4d89-ac10-a4d686a6eaab"
      },
      "source": [
        "import os\n",
        "\n",
        "# Define the path to the labels directory\n",
        "labels_dir = './trash-detection/Dataset/labels/train'\n",
        "\n",
        "# Initialize an empty dictionary to store class counts\n",
        "# and a variable to store the total number of instances\n",
        "class_counts = {i: 0 for i in range(len(class_names))}\n",
        "total_instances = 0\n",
        "\n",
        "# List all files in the labels directory\n",
        "all_label_files = os.listdir(labels_dir)\n",
        "\n",
        "# Filter for .txt files (YOLO label files)\n",
        "label_files = [f for f in all_label_files if f.endswith('.txt')]\n",
        "\n",
        "print(f\"Processing {len(label_files)} label files...\")\n",
        "\n",
        "# Iterate through each identified label file\n",
        "for filename in label_files:\n",
        "    filepath = os.path.join(labels_dir, filename)\n",
        "    with open(filepath, 'r') as file:\n",
        "        for line in file:\n",
        "            # Increment total instances for each line (each bounding box)\n",
        "            total_instances += 1\n",
        "\n",
        "            # Extract class ID (first element in the line)\n",
        "            try:\n",
        "                class_id = int(line.strip().split(' ')[0])\n",
        "                # Increment the count for this class ID\n",
        "                class_counts[class_id] = class_counts.get(class_id, 0) + 1\n",
        "            except ValueError as e:\n",
        "                print(f\"Warning: Could not parse class ID in file {filename}, line: {line.strip()}. Error: {e}\")\n",
        "            except IndexError as e:\n",
        "                print(f\"Warning: Empty line or unexpected format in file {filename}, line: {line.strip()}. Error: {e}\")\n",
        "\n",
        "print(\"\\n--- Dataset Class Analysis ---\")\n",
        "print(f\"Total instances (bounding boxes detected): {total_instances}\")\n",
        "print(\"Class distribution:\")\n",
        "\n",
        "# Print class names with their counts\n",
        "for class_id, count in class_counts.items():\n",
        "    if class_id < len(class_names):\n",
        "        class_name = class_names[class_id]\n",
        "        print(f\"  - {class_name} (ID {class_id}): {count} instances\")\n",
        "    else:\n",
        "        print(f\"  - Unknown Class (ID {class_id}): {count} instances (not in data.yaml)\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 1229 label files...\n",
            "\n",
            "--- Dataset Class Analysis ---\n",
            "Total instances (bounding boxes detected): 7900\n",
            "Class distribution:\n",
            "  - dirt (ID 0): 1418 instances\n",
            "  - liquid (ID 1): 494 instances\n",
            "  - marks (ID 2): 3373 instances\n",
            "  - trash (ID 3): 2615 instances\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a19ad52"
      },
      "source": [
        "### Dataset Summary\n",
        "\n",
        "This section provides a summary of the `trash-detection` dataset, based on the analysis of its structure and label files.\n",
        "\n",
        "-   **Overall Dataset Size:**\n",
        "    -   Total number of label files processed: **1229**\n",
        "    -   Total number of instances (bounding boxes) detected: **7900**\n",
        "\n",
        "-   **Detected Classes:**\n",
        "    -   The dataset contains **4** distinct classes.\n",
        "    -   Class Names: `['dirt', 'liquid', 'marks', 'trash']`\n",
        "\n",
        "-   **Class Distribution (Instance Count per Class):**\n",
        "    -   `dirt`: 1418 instances\n",
        "    -   `liquid`: 494 instances\n",
        "    -   `marks`: 3373 instances\n",
        "    -   `trash`: 2615 instances\n",
        "\n",
        "This summary indicates that the `marks` class has the highest number of instances, followed by `trash`, `dirt`, and `liquid` having the least."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the path to the labels directory\n",
        "labels_dir = './trash-detection/Dataset/labels/val'\n",
        "\n",
        "# Initialize an empty dictionary to store class counts\n",
        "# and a variable to store the total number of instances\n",
        "class_counts = {i: 0 for i in range(len(class_names))}\n",
        "total_instances = 0\n",
        "\n",
        "# List all files in the labels directory\n",
        "all_label_files = os.listdir(labels_dir)\n",
        "\n",
        "# Filter for .txt files (YOLO label files)\n",
        "label_files = [f for f in all_label_files if f.endswith('.txt')]\n",
        "\n",
        "print(f\"Processing {len(label_files)} label files...\")\n",
        "\n",
        "# Iterate through each identified label file\n",
        "for filename in label_files:\n",
        "    filepath = os.path.join(labels_dir, filename)\n",
        "    with open(filepath, 'r') as file:\n",
        "        for line in file:\n",
        "            # Increment total instances for each line (each bounding box)\n",
        "            total_instances += 1\n",
        "\n",
        "            # Extract class ID (first element in the line)\n",
        "            try:\n",
        "                class_id = int(line.strip().split(' ')[0])\n",
        "                # Increment the count for this class ID\n",
        "                class_counts[class_id] = class_counts.get(class_id, 0) + 1\n",
        "            except ValueError as e:\n",
        "                print(f\"Warning: Could not parse class ID in file {filename}, line: {line.strip()}. Error: {e}\")\n",
        "            except IndexError as e:\n",
        "                print(f\"Warning: Empty line or unexpected format in file {filename}, line: {line.strip()}. Error: {e}\")\n",
        "\n",
        "print(\"\\n--- Dataset Class Analysis ---\")\n",
        "print(f\"Total instances (bounding boxes detected): {total_instances}\")\n",
        "print(\"Class distribution:\")\n",
        "\n",
        "# Print class names with their counts\n",
        "for class_id, count in class_counts.items():\n",
        "    if class_id < len(class_names):\n",
        "        class_name = class_names[class_id]\n",
        "        print(f\"  - {class_name} (ID {class_id}): {count} instances\")\n",
        "    else:\n",
        "        print(f\"  - Unknown Class (ID {class_id}): {count} instances (not in data.yaml)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmPr494PMh82",
        "outputId": "00d5f477-3e81-4885-c374-8326c883103d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing 308 label files...\n",
            "\n",
            "--- Dataset Class Analysis ---\n",
            "Total instances (bounding boxes detected): 2018\n",
            "Class distribution:\n",
            "  - dirt (ID 0): 367 instances\n",
            "  - liquid (ID 1): 140 instances\n",
            "  - marks (ID 2): 822 instances\n",
            "  - trash (ID 3): 689 instances\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lJYjnuALuxap"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34035d8a"
      },
      "source": [
        "# Task\n",
        "Identify the minority classes from the training set based on their instance counts, aiming to balance the dataset by targeting classes with significantly fewer instances for augmentation. Specifically, calculate the average instance count across all classes in the training set and identify classes that fall below this average as candidates for augmentation, outputting the names of these classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a1e88cf"
      },
      "source": [
        "## Identify Minority Classes for Augmentation\n",
        "\n",
        "### Subtask:\n",
        "Using the previously determined class counts for the training set, identify which classes are underrepresented and require data augmentation to achieve a more balanced distribution. This step will define the target classes for augmentation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60bbeac5"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to calculate the average instance count for the training set and then identify classes with counts below this average to determine minority classes for augmentation, as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abd43685",
        "outputId": "604d687a-5f34-468b-82fb-9c300b6a070f"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Class counts for the training set (from previous analysis in cell 1bc2ff07)\n",
        "train_class_counts = {0: 1418, 1: 494, 2: 3373, 3: 2615}\n",
        "\n",
        "# Total number of instances in the training set\n",
        "total_train_instances = sum(train_class_counts.values())\n",
        "\n",
        "# Number of classes\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Calculate the average instance count per class\n",
        "average_instance_count = total_train_instances / num_classes\n",
        "\n",
        "# Initialize a list to store minority class names\n",
        "minority_classes = []\n",
        "\n",
        "# Identify minority classes\n",
        "for class_id, count in train_class_counts.items():\n",
        "    if count < average_instance_count:\n",
        "        minority_classes.append(class_names[class_id])\n",
        "\n",
        "print(f\"Total instances in training set: {total_train_instances}\")\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Average instance count per class: {average_instance_count:.2f}\")\n",
        "print(f\"Identified minority classes for augmentation: {minority_classes}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total instances in training set: 7900\n",
            "Number of classes: 4\n",
            "Average instance count per class: 1975.00\n",
            "Identified minority classes for augmentation: ['dirt', 'liquid']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2272470"
      },
      "source": [
        "## Prepare Output Directories for Augmented Data\n",
        "\n",
        "### Subtask:\n",
        "Create new directories for storing the augmented images and their corresponding label files. This ensures that the original dataset remains untouched and allows for clear separation of augmented data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "533c096b"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to define the paths for the original and augmented training image and label directories and then create the augmented directories using `os.makedirs`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "867f34f8",
        "outputId": "4969704d-05c6-4910-a172-d3fc2ceb7999"
      },
      "source": [
        "import os\n",
        "\n",
        "# Define base paths for original training data\n",
        "original_train_images_dir = './trash-detection/Dataset/images/train'\n",
        "original_train_labels_dir = './trash-detection/Dataset/labels/train'\n",
        "\n",
        "# Define new paths for augmented training data\n",
        "augmented_train_images_dir = './trash-detection/Dataset/images/augmented_train'\n",
        "augmented_train_labels_dir = './trash-detection/Dataset/labels/augmented_train'\n",
        "\n",
        "# Create directories for augmented images and labels\n",
        "os.makedirs(augmented_train_images_dir, exist_ok=True)\n",
        "os.makedirs(augmented_train_labels_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Created directory: {augmented_train_images_dir}\")\n",
        "print(f\"Created directory: {augmented_train_labels_dir}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created directory: ./trash-detection/Dataset/images/augmented_train\n",
            "Created directory: ./trash-detection/Dataset/labels/augmented_train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7395ac85"
      },
      "source": [
        "## Implement Data Augmentation for Images and YOLO Labels\n",
        "\n",
        "### Subtask:\n",
        "Develop Python code to perform data augmentation specifically for the identified minority classes. This will involve loading images and their associated YOLO format label files, applying geometric transformations (horizontal/vertical flips, rotations) and photometric transformations (brightness changes), crucially transforming the bounding box coordinates within the YOLO label files to match the applied image augmentations, and saving the augmented images and their transformed label files into the newly created output directories.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "800f8ce8"
      },
      "source": [
        "**Reasoning**:\n",
        "I will start by importing the necessary libraries for image manipulation (PIL), numerical operations (numpy), file system interactions (os), and randomness (random). These libraries are fundamental for developing the data augmentation functions and handling file paths.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "064929fc",
        "outputId": "ac16fb01-cf48-4ad5-f179-7b47a25180d5"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image, ImageEnhance\n",
        "import random\n",
        "\n",
        "print(\"Necessary libraries imported: os, numpy, PIL (Image, ImageEnhance), random.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Necessary libraries imported: os, numpy, PIL (Image, ImageEnhance), random.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e31109a"
      },
      "source": [
        "**Reasoning**:\n",
        "I will define utility functions to read and write YOLO label files, as these are crucial for parsing existing bounding box annotations and saving transformed ones after augmentation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8db18c93",
        "outputId": "ac96814b-6f19-4d63-df67-bcf0a9a1b933"
      },
      "source": [
        "def read_yolo_labels(label_filepath):\n",
        "    \"\"\"Reads a YOLO format label file and returns a list of bounding boxes.\n",
        "    Each bounding box is [class_id, x_center, y_center, width, height] (normalized).\n",
        "    \"\"\"\n",
        "    bboxes = []\n",
        "    if not os.path.exists(label_filepath):\n",
        "        return bboxes\n",
        "    with open(label_filepath, 'r') as f:\n",
        "        for line in f:\n",
        "            parts = list(map(float, line.strip().split()))\n",
        "            if len(parts) == 5:\n",
        "                bboxes.append(parts)\n",
        "    return bboxes\n",
        "\n",
        "def write_yolo_labels(label_filepath, bboxes):\n",
        "    \"\"\"Writes a list of bounding boxes to a YOLO format label file.\n",
        "    Each bounding box is [class_id, x_center, y_center, width, height] (normalized).\n",
        "    \"\"\"\n",
        "    with open(label_filepath, 'w') as f:\n",
        "        for bbox in bboxes:\n",
        "            # Ensure class_id is an integer, others are floats formatted to 6 decimal places\n",
        "            f.write(f\"{int(bbox[0])} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f} {bbox[4]:.6f}\\n\")\n",
        "\n",
        "print(\"Utility functions 'read_yolo_labels' and 'write_yolo_labels' defined.\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Utility functions 'read_yolo_labels' and 'write_yolo_labels' defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7962d29"
      },
      "source": [
        "**Reasoning**:\n",
        "I will define the geometric augmentation functions (`horizontal_flip`, `vertical_flip`, `rotate_90_clockwise`) that transform both the image and its corresponding YOLO bounding box coordinates, and a photometric augmentation function (`adjust_brightness`) that only modifies the image, as instructed. These functions are crucial for preparing the data for augmentation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86d543ad",
        "outputId": "91d6156b-995e-4f91-bc5c-7750e04c8f15"
      },
      "source": [
        "def horizontal_flip(image, bboxes):\n",
        "    \"\"\"Flips the image horizontally and updates bounding box coordinates.\"\"\"\n",
        "    # Flip image\n",
        "    flipped_image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "    # Update bounding box coordinates\n",
        "    flipped_bboxes = []\n",
        "    for bbox in bboxes:\n",
        "        class_id, x_center, y_center, width, height = bbox\n",
        "        new_x_center = 1 - x_center  # Flip x-coordinate\n",
        "        flipped_bboxes.append([class_id, new_x_center, y_center, width, height])\n",
        "    return flipped_image, flipped_bboxes\n",
        "\n",
        "def vertical_flip(image, bboxes):\n",
        "    \"\"\"Flips the image vertically and updates bounding box coordinates.\"\"\"\n",
        "    # Flip image\n",
        "    flipped_image = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
        "\n",
        "    # Update bounding box coordinates\n",
        "    flipped_bboxes = []\n",
        "    for bbox in bboxes:\n",
        "        class_id, x_center, y_center, width, height = bbox\n",
        "        new_y_center = 1 - y_center  # Flip y-coordinate\n",
        "        flipped_bboxes.append([class_id, x_center, new_y_center, width, height])\n",
        "    return flipped_image, flipped_bboxes\n",
        "\n",
        "def rotate_90_clockwise(image, bboxes):\n",
        "    \"\"\"Rotates the image 90 degrees clockwise and updates bounding box coordinates.\"\"\"\n",
        "    # Rotate image\n",
        "    rotated_image = image.transpose(Image.ROTATE_270) # ROTATE_270 is 90 degrees clockwise\n",
        "\n",
        "    # Update bounding box coordinates\n",
        "    rotated_bboxes = []\n",
        "    for bbox in bboxes:\n",
        "        class_id, x_center, y_center, width, height = bbox\n",
        "        # New x_center becomes 1 - original y_center\n",
        "        # New y_center becomes original x_center\n",
        "        # New width becomes original height\n",
        "        # New height becomes original width\n",
        "        new_x_center = 1 - y_center\n",
        "        new_y_center = x_center\n",
        "        new_width = height\n",
        "        new_height = width\n",
        "        rotated_bboxes.append([class_id, new_x_center, new_y_center, new_width, new_height])\n",
        "    return rotated_image, rotated_bboxes\n",
        "\n",
        "def adjust_brightness(image, bboxes, factor):\n",
        "    \"\"\"Adjusts image brightness. Bounding boxes remain unchanged.\"\"\"\n",
        "    enhancer = ImageEnhance.Brightness(image)\n",
        "    brightened_image = enhancer.enhance(factor)\n",
        "    return brightened_image, bboxes\n",
        "\n",
        "print(\"Data augmentation functions (horizontal_flip, vertical_flip, rotate_90_clockwise, adjust_brightness) defined.\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data augmentation functions (horizontal_flip, vertical_flip, rotate_90_clockwise, adjust_brightness) defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1ed40d3"
      },
      "source": [
        "**Reasoning**:\n",
        "I will now iterate through the original training images and their labels, identify images containing minority classes, apply the defined augmentation techniques (horizontal flip, 90-degree clockwise rotation, and brightness adjustment) to these images and their bounding boxes, and save the augmented images and their corresponding transformed label files to the designated augmented directories.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd7258dc",
        "outputId": "e4b508c7-043d-4fe4-f981-fd481f634b3b"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image, ImageEnhance\n",
        "import random\n",
        "\n",
        "# Assuming class_names, minority_classes, original_train_images_dir, original_train_labels_dir,\n",
        "# augmented_train_images_dir, augmented_train_labels_dir are defined from previous steps.\n",
        "\n",
        "print(f\"Starting data augmentation for minority classes: {minority_classes}\")\n",
        "print(f\"Original images directory: {original_train_images_dir}\")\n",
        "print(f\"Original labels directory: {original_train_labels_dir}\")\n",
        "print(f\"Augmented images directory: {augmented_train_images_dir}\")\n",
        "print(f\"Augmented labels directory: {augmented_train_labels_dir}\")\n",
        "\n",
        "augmented_count = 0\n",
        "\n",
        "# Get a list of all image files in the original training directory\n",
        "image_files = [f for f in os.listdir(original_train_images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "for img_filename in image_files:\n",
        "    base_filename, _ = os.path.splitext(img_filename)\n",
        "    img_filepath = os.path.join(original_train_images_dir, img_filename)\n",
        "    label_filepath = os.path.join(original_train_labels_dir, base_filename + '.txt')\n",
        "\n",
        "    # Load image and labels\n",
        "    try:\n",
        "        image = Image.open(img_filepath).convert('RGB')\n",
        "        bboxes = read_yolo_labels(label_filepath)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {img_filepath} or {label_filepath}: {e}\")\n",
        "        continue\n",
        "\n",
        "    if not bboxes:\n",
        "        # Skip if no bounding boxes are found\n",
        "        continue\n",
        "\n",
        "    # Check if this image contains any minority class instances\n",
        "    contains_minority_class = False\n",
        "    for bbox in bboxes:\n",
        "        class_id = int(bbox[0])\n",
        "        if class_names[class_id] in minority_classes:\n",
        "            contains_minority_class = True\n",
        "            break\n",
        "\n",
        "    # Only augment images that contain minority classes\n",
        "    if contains_minority_class:\n",
        "        # --- Apply Augmentations ---\n",
        "\n",
        "        # 1. Horizontal Flip\n",
        "        flipped_image, flipped_bboxes = horizontal_flip(image, bboxes)\n",
        "        flipped_img_filename = f\"{base_filename}_hf.jpg\"\n",
        "        flipped_label_filename = f\"{base_filename}_hf.txt\"\n",
        "        flipped_image.save(os.path.join(augmented_train_images_dir, flipped_img_filename))\n",
        "        write_yolo_labels(os.path.join(augmented_train_labels_dir, flipped_label_filename), flipped_bboxes)\n",
        "        augmented_count += 1\n",
        "\n",
        "        # 2. Rotate 90 degrees clockwise\n",
        "        rotated_image, rotated_bboxes = rotate_90_clockwise(image, bboxes)\n",
        "        rotated_img_filename = f\"{base_filename}_r90.jpg\"\n",
        "        rotated_label_filename = f\"{base_filename}_r90.txt\"\n",
        "        rotated_image.save(os.path.join(augmented_train_images_dir, rotated_img_filename))\n",
        "        write_yolo_labels(os.path.join(augmented_train_labels_dir, rotated_label_filename), rotated_bboxes)\n",
        "        augmented_count += 1\n",
        "\n",
        "        # 3. Adjust Brightness (randomly dim or brighten)\n",
        "        brightness_factor = random.choice([0.4,0.5,0.6,0.7,0.8,1.2,1.3,1.4,1.5,1.6]) # Factor between 0.7 (dim) and 1.3 (bright)\n",
        "        brightened_image, brightened_bboxes = adjust_brightness(image, bboxes, brightness_factor)\n",
        "        brightened_img_filename = f\"{base_filename}_br.jpg\"\n",
        "        brightened_label_filename = f\"{base_filename}_br.txt\"\n",
        "        brightened_image.save(os.path.join(augmented_train_images_dir, brightened_img_filename))\n",
        "        write_yolo_labels(os.path.join(augmented_train_labels_dir, brightened_label_filename), brightened_bboxes)\n",
        "        augmented_count += 1\n",
        "\n",
        "print(f\"Finished data augmentation. Total augmented images/labels generated: {augmented_count}\")\n",
        "print(f\"Augmented data stored in: {augmented_train_images_dir} and {augmented_train_labels_dir}\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data augmentation for minority classes: ['dirt', 'liquid']\n",
            "Original images directory: ./trash-detection/Dataset/images/train\n",
            "Original labels directory: ./trash-detection/Dataset/labels/train\n",
            "Augmented images directory: ./trash-detection/Dataset/images/augmented_train\n",
            "Augmented labels directory: ./trash-detection/Dataset/labels/augmented_train\n",
            "Finished data augmentation. Total augmented images/labels generated: 1653\n",
            "Augmented data stored in: ./trash-detection/Dataset/images/augmented_train and ./trash-detection/Dataset/labels/augmented_train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95c3b80e"
      },
      "source": [
        "## Verify New Class Balance Post-Augmentation\n",
        "\n",
        "### Subtask:\n",
        "After applying augmentations, re-run the class counting logic on the combined original and augmented datasets. This step will confirm whether the dataset has achieved a more balanced distribution across classes, providing updated instance counts for each class.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6a3ed46"
      },
      "source": [
        "**Reasoning**:\n",
        "I will re-run the class counting logic to include the newly augmented data, aggregating counts from both the original and augmented datasets to verify the new class balance, and then print a summary of the combined distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c55a4d7",
        "outputId": "846e14c4-98ef-4897-b144-19bf1443d2a5"
      },
      "source": [
        "import os\n",
        "\n",
        "# 1. Initialize combined_class_counts with original training counts\n",
        "# train_class_counts is already defined from previous steps (cell abd43685)\n",
        "combined_class_counts = train_class_counts.copy()\n",
        "\n",
        "# Initialize a variable to store the total number of instances from augmented data\n",
        "total_augmented_instances = 0\n",
        "\n",
        "# 2. Define the path to the augmented labels directory\n",
        "# augmented_train_labels_dir is already defined from previous steps (cell 867f34f8)\n",
        "\n",
        "print(f\"Processing augmented labels from: {augmented_train_labels_dir}\")\n",
        "\n",
        "# 3. Get a list of all .txt files (label files) within the augmented_train_labels_dir\n",
        "all_augmented_label_files = os.listdir(augmented_train_labels_dir)\n",
        "augmented_label_files = [f for f in all_augmented_label_files if f.endswith('.txt')]\n",
        "\n",
        "print(f\"Found {len(augmented_label_files)} augmented label files.\")\n",
        "\n",
        "# 4. Iterate through each augmented label file\n",
        "for filename in augmented_label_files:\n",
        "    filepath = os.path.join(augmented_train_labels_dir, filename)\n",
        "    with open(filepath, 'r') as file:\n",
        "        for line in file:\n",
        "            # Increment total augmented instances for each line (each bounding box)\n",
        "            total_augmented_instances += 1\n",
        "\n",
        "            # Extract class ID (first element in the line)\n",
        "            try:\n",
        "                class_id = int(line.strip().split(' ')[0])\n",
        "                # Increment the count for this class ID in the combined dictionary\n",
        "                combined_class_counts[class_id] = combined_class_counts.get(class_id, 0) + 1\n",
        "            except ValueError as e:\n",
        "                print(f\"Warning: Could not parse class ID in augmented file {filename}, line: {line.strip()}. Error: {e}\")\n",
        "            except IndexError as e:\n",
        "                print(f\"Warning: Empty line or unexpected format in augmented file {filename}, line: {line.strip()}. Error: {e}\")\n",
        "\n",
        "# 5. Print the total number of instances from the augmented data\n",
        "print(f\"\\nTotal instances added from augmented data: {total_augmented_instances}\")\n",
        "\n",
        "# Calculate total instances in the combined dataset\n",
        "total_combined_instances = sum(combined_class_counts.values())\n",
        "\n",
        "print(\"\\n--- Combined Dataset Class Analysis (Original + Augmented) ---\")\n",
        "print(f\"Total instances (bounding boxes detected) in combined dataset: {total_combined_instances}\")\n",
        "print(\"Combined Class distribution:\")\n",
        "\n",
        "# 6. Print the combined_class_counts dictionary\n",
        "for class_id, count in combined_class_counts.items():\n",
        "    if class_id < len(class_names):\n",
        "        class_name_str = class_names[class_id]\n",
        "        print(f\"  - {class_name_str} (ID {class_id}): {count} instances\")\n",
        "    else:\n",
        "        print(f\"  - Unknown Class (ID {class_id}): {count} instances (not in data.yaml)\")\n",
        "\n",
        "# 7. Print a summary indicating the improvement in class balance\n",
        "print(\"\\n--- Class Balance Improvement Summary ---\")\n",
        "print(\"Original training class distribution:\")\n",
        "for class_id, count in train_class_counts.items():\n",
        "    print(f\"  - {class_names[class_id]} (ID {class_id}): {count} instances\")\n",
        "\n",
        "\n",
        "# Calculate average instance count for the combined dataset for comparison\n",
        "average_combined_instance_count = total_combined_instances / num_classes\n",
        "\n",
        "print(f\"\\nAverage instance count per class in original training set: {average_instance_count:.2f}\")\n",
        "print(f\"Average instance count per class in combined dataset: {average_combined_instance_count:.2f}\")\n",
        "\n",
        "new_minority_classes = []\n",
        "for class_id, count in combined_class_counts.items():\n",
        "    if count < average_combined_instance_count:\n",
        "        new_minority_classes.append(class_names[class_id])\n",
        "\n",
        "if not new_minority_classes:\n",
        "    print(\"All classes are now above or very close to the average instance count, indicating improved balance.\")\n",
        "else:\n",
        "    print(f\"Classes still below the new average: {new_minority_classes}\")\n",
        "    print(\"Further augmentation might be beneficial for these classes.\")\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing augmented labels from: ./trash-detection/Dataset/labels/augmented_train\n",
            "Found 1653 augmented label files.\n",
            "\n",
            "Total instances added from augmented data: 14193\n",
            "\n",
            "--- Combined Dataset Class Analysis (Original + Augmented) ---\n",
            "Total instances (bounding boxes detected) in combined dataset: 22093\n",
            "Combined Class distribution:\n",
            "  - dirt (ID 0): 5672 instances\n",
            "  - liquid (ID 1): 1976 instances\n",
            "  - marks (ID 2): 11830 instances\n",
            "  - trash (ID 3): 2615 instances\n",
            "\n",
            "--- Class Balance Improvement Summary ---\n",
            "Original training class distribution:\n",
            "  - dirt (ID 0): 1418 instances\n",
            "  - liquid (ID 1): 494 instances\n",
            "  - marks (ID 2): 3373 instances\n",
            "  - trash (ID 3): 2615 instances\n",
            "\n",
            "Average instance count per class in original training set: 1975.00\n",
            "Average instance count per class in combined dataset: 5523.25\n",
            "Classes still below the new average: ['liquid', 'trash']\n",
            "Further augmentation might be beneficial for these classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9473bb0b"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Provide a comprehensive summary of the data augmentation process, including the types of augmentations applied, the classes targeted, and the resulting class distribution, highlighting how the dataset balance has been improved.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b02e365"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "1.  **Which classes were targeted for augmentation?**\n",
        "    The minority classes targeted for augmentation were 'dirt' and 'liquid', as their initial instance counts (1418 and 494 respectively) were below the average instance count of 1975.00 across all classes in the original training set.\n",
        "2.  **Did the data augmentation process improve dataset balance?**\n",
        "    Yes, the data augmentation process significantly improved the dataset balance, especially for the targeted minority classes. The 'dirt' class increased from 1418 to 5672 instances, and the 'liquid' class increased from 494 to 1976 instances. The overall average instance count per class rose from 1975.00 to 5523.25. However, 'liquid' and 'trash' classes still remain below the new average, indicating room for further improvement.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   Initially, the training dataset contained a total of 7900 instances across 4 classes, with an average of 1975.00 instances per class.\n",
        "*   The minority classes identified for augmentation were 'dirt' (1418 instances) and 'liquid' (494 instances), as they fell below the initial average.\n",
        "*   The data augmentation process applied the following transformations to images containing these minority classes:\n",
        "    *   Horizontal Flip\n",
        "    *   90-degree Clockwise Rotation\n",
        "    *   Brightness Adjustment (random factor between 0.7 and 1.3)\n",
        "*   A total of 1653 augmented images and their corresponding label files were generated, adding 14,193 new bounding box instances to the dataset.\n",
        "*   After augmentation, the combined dataset consists of 22,093 instances, with an increased average of 5523.25 instances per class.\n",
        "*   The class distribution dramatically improved for the targeted classes:\n",
        "    *   **dirt**: Increased from 1418 to 5672 instances.\n",
        "    *   **liquid**: Increased from 494 to 1976 instances.\n",
        "    *   **marks**: Increased from 3373 to 11830 instances (as images containing minority classes could also contain 'marks' instances which were then augmented).\n",
        "    *   **trash**: Remained at 2615 instances (as it was not a minority class and images primarily containing 'trash' were not augmented).\n",
        "*   Despite the significant improvements, the 'liquid' (1976 instances) and 'trash' (2615 instances) classes are still below the new average instance count of 5523.25.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The data augmentation successfully boosted the representation of the 'dirt' and 'liquid' classes, leading to a more balanced dataset overall, which is crucial for improving the performance of object detection models, especially for underrepresented categories.\n",
        "*   To achieve even greater balance, consider applying further targeted augmentation strategies specifically for the 'liquid' and 'trash' classes, perhaps using more aggressive augmentation policies or generating more augmented samples for these particular classes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aa5c19c"
      },
      "source": [
        "# Task\n",
        "Refine the data augmentation process for the `trash-detection` dataset by modifying the augmentation logic to *only* save bounding boxes corresponding to minority classes in the augmented label files. After this refinement, re-verify the new class balance by re-running the class counting logic on the combined original and corrected augmented datasets. Finally, provide a comprehensive summary of the refined data augmentation process, including the types of augmentations applied, the specific classes targeted, and the resulting class distribution, highlighting how the dataset balance has been improved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ab9a155"
      },
      "source": [
        "## Refine Data Augmentation Logic\n",
        "\n",
        "### Subtask:\n",
        "Modify the data augmentation implementation to save only bounding boxes corresponding to minority classes in the augmented label files, excluding bounding boxes of non-minority classes from these augmented files.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37839f00"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to modify the data augmentation loop to filter bounding boxes, ensuring that only those corresponding to minority classes are passed to the augmentation functions and subsequently saved in the augmented label files, as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96bc427e",
        "outputId": "eaaeae09-fdd3-4e0d-ab4c-a5327a7b8c06"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image, ImageEnhance\n",
        "import random\n",
        "\n",
        "# Assuming class_names, minority_classes, original_train_images_dir, original_train_labels_dir,\n",
        "# augmented_train_images_dir, augmented_train_labels_dir are defined from previous steps.\n",
        "\n",
        "print(f\"Starting data augmentation for minority classes: {minority_classes}\")\n",
        "print(f\"Original images directory: {original_train_images_dir}\")\n",
        "print(f\"Original labels directory: {original_train_labels_dir}\")\n",
        "print(f\"Augmented images directory: {augmented_train_images_dir}\")\n",
        "print(f\"Augmented labels directory: {augmented_train_labels_dir}\")\n",
        "\n",
        "augmented_count = 0\n",
        "\n",
        "# Get a list of all image files in the original training directory\n",
        "image_files = [f for f in os.listdir(original_train_images_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "for img_filename in image_files:\n",
        "    base_filename, _ = os.path.splitext(img_filename)\n",
        "    img_filepath = os.path.join(original_train_images_dir, img_filename)\n",
        "    label_filepath = os.path.join(original_train_labels_dir, base_filename + '.txt')\n",
        "\n",
        "    # Load image and labels\n",
        "    try:\n",
        "        image = Image.open(img_filepath).convert('RGB')\n",
        "        bboxes = read_yolo_labels(label_filepath)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {img_filepath} or {label_filepath}: {e}\")\n",
        "        continue\n",
        "\n",
        "    if not bboxes:\n",
        "        # Skip if no bounding boxes are found\n",
        "        continue\n",
        "\n",
        "    # Check if this image contains any minority class instances\n",
        "    contains_minority_class = False\n",
        "    for bbox in bboxes:\n",
        "        class_id = int(bbox[0])\n",
        "        if class_names[class_id] in minority_classes:\n",
        "            contains_minority_class = True\n",
        "            break\n",
        "\n",
        "    # Only augment images that contain minority classes\n",
        "    if contains_minority_class:\n",
        "        # Filter bboxes to include only minority classes\n",
        "        minority_class_bboxes = [bbox for bbox in bboxes if class_names[int(bbox[0])] in minority_classes]\n",
        "\n",
        "        # --- Apply Augmentations ---\n",
        "\n",
        "        # 1. Horizontal Flip\n",
        "        flipped_image, flipped_bboxes = horizontal_flip(image, minority_class_bboxes)\n",
        "        flipped_img_filename = f\"{base_filename}_hf.jpg\"\n",
        "        flipped_label_filename = f\"{base_filename}_hf.txt\"\n",
        "        flipped_image.save(os.path.join(augmented_train_images_dir, flipped_img_filename))\n",
        "        write_yolo_labels(os.path.join(augmented_train_labels_dir, flipped_label_filename), flipped_bboxes)\n",
        "        augmented_count += 1\n",
        "\n",
        "        # 2. Rotate 90 degrees clockwise\n",
        "        rotated_image, rotated_bboxes = rotate_90_clockwise(image, minority_class_bboxes)\n",
        "        rotated_img_filename = f\"{base_filename}_r90.jpg\"\n",
        "        rotated_label_filename = f\"{base_filename}_r90.txt\"\n",
        "        rotated_image.save(os.path.join(augmented_train_images_dir, rotated_img_filename))\n",
        "        write_yolo_labels(os.path.join(augmented_train_labels_dir, rotated_label_filename), rotated_bboxes)\n",
        "        augmented_count += 1\n",
        "\n",
        "        # 3. Adjust Brightness (randomly dim or brighten)\n",
        "        brightness_factor = random.uniform(0.7, 1.3) # Factor between 0.7 (dim) and 1.3 (bright)\n",
        "        brightened_image, brightened_bboxes = adjust_brightness(image, minority_class_bboxes, brightness_factor)\n",
        "        brightened_img_filename = f\"{base_filename}_br.jpg\"\n",
        "        brightened_label_filename = f\"{base_filename}_br.txt\"\n",
        "        brightened_image.save(os.path.join(augmented_train_images_dir, brightened_img_filename))\n",
        "        write_yolo_labels(os.path.join(augmented_train_labels_dir, brightened_label_filename), brightened_bboxes)\n",
        "        augmented_count += 1\n",
        "\n",
        "print(f\"Finished data augmentation. Total augmented images/labels generated: {augmented_count}\")\n",
        "print(f\"Augmented data stored in: {augmented_train_images_dir} and {augmented_train_labels_dir}\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting data augmentation for minority classes: ['dirt', 'liquid']\n",
            "Original images directory: ./trash-detection/Dataset/images/train\n",
            "Original labels directory: ./trash-detection/Dataset/labels/train\n",
            "Augmented images directory: ./trash-detection/Dataset/images/augmented_train\n",
            "Augmented labels directory: ./trash-detection/Dataset/labels/augmented_train\n",
            "Finished data augmentation. Total augmented images/labels generated: 1653\n",
            "Augmented data stored in: ./trash-detection/Dataset/images/augmented_train and ./trash-detection/Dataset/labels/augmented_train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d03633f"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block has already implemented the modification to save only minority class bounding boxes. Now I need to re-verify the class balance by re-running the class counting logic on the combined original and augmented datasets to confirm the effect of the refined augmentation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12efac04",
        "outputId": "dc167554-019f-4398-ca7b-94f38218dc8b"
      },
      "source": [
        "import os\n",
        "\n",
        "# 1. Initialize combined_class_counts with original training counts\n",
        "# train_class_counts is already defined from previous steps (cell abd43685)\n",
        "combined_class_counts = train_class_counts.copy()\n",
        "\n",
        "# Initialize a variable to store the total number of instances from augmented data\n",
        "total_augmented_instances = 0\n",
        "\n",
        "# 2. Define the path to the augmented labels directory\n",
        "# augmented_train_labels_dir is already defined from previous steps (cell 867f34f8)\n",
        "\n",
        "print(f\"Processing augmented labels from: {augmented_train_labels_dir}\")\n",
        "\n",
        "# 3. Get a list of all .txt files (label files) within the augmented_train_labels_dir\n",
        "all_augmented_label_files = os.listdir(augmented_train_labels_dir)\n",
        "augmented_label_files = [f for f in all_augmented_label_files if f.endswith('.txt')]\n",
        "\n",
        "print(f\"Found {len(augmented_label_files)} augmented label files.\")\n",
        "\n",
        "# 4. Iterate through each augmented label file\n",
        "for filename in augmented_label_files:\n",
        "    filepath = os.path.join(augmented_train_labels_dir, filename)\n",
        "    with open(filepath, 'r') as file:\n",
        "        for line in file:\n",
        "            # Increment total augmented instances for each line (each bounding box)\n",
        "            total_augmented_instances += 1\n",
        "\n",
        "            # Extract class ID (first element in the line)\n",
        "            try:\n",
        "                class_id = int(line.strip().split(' ')[0])\n",
        "                # Increment the count for this class ID in the combined dictionary\n",
        "                combined_class_counts[class_id] = combined_class_counts.get(class_id, 0) + 1\n",
        "            except ValueError as e:\n",
        "                print(f\"Warning: Could not parse class ID in augmented file {filename}, line: {line.strip()}. Error: {e}\")\n",
        "            except IndexError as e:\n",
        "                print(f\"Warning: Empty line or unexpected format in augmented file {filename}, line: {line.strip()}. Error: {e}\")\n",
        "\n",
        "# 5. Print the total number of instances from the augmented data\n",
        "print(f\"\\nTotal instances added from augmented data: {total_augmented_instances}\")\n",
        "\n",
        "# Calculate total instances in the combined dataset\n",
        "total_combined_instances = sum(combined_class_counts.values())\n",
        "\n",
        "print(\"\\n--- Combined Dataset Class Analysis (Original + Augmented) ---\")\n",
        "print(f\"Total instances (bounding boxes detected) in combined dataset: {total_combined_instances}\")\n",
        "print(\"Combined Class distribution:\")\n",
        "\n",
        "# 6. Print the combined_class_counts dictionary\n",
        "for class_id, count in combined_class_counts.items():\n",
        "    if class_id < len(class_names):\n",
        "        class_name_str = class_names[class_id]\n",
        "        print(f\"  - {class_name_str} (ID {class_id}): {count} instances\")\n",
        "    else:\n",
        "        print(f\"  - Unknown Class (ID {class_id}): {count} instances (not in data.yaml)\")\n",
        "\n",
        "# 7. Print a summary indicating the improvement in class balance\n",
        "print(\"\\n--- Class Balance Improvement Summary ---\")\n",
        "print(\"Original training class distribution:\")\n",
        "for class_id, count in train_class_counts.items():\n",
        "    print(f\"  - {class_names[class_id]} (ID {class_id}): {count} instances\")\n",
        "\n",
        "\n",
        "# Calculate average instance count for the combined dataset for comparison\n",
        "average_combined_instance_count = total_combined_instances / num_classes\n",
        "\n",
        "print(f\"\\nAverage instance count per class in original training set: {average_instance_count:.2f}\")\n",
        "print(f\"Average instance count per class in combined dataset: {average_combined_instance_count:.2f}\")\n",
        "\n",
        "new_minority_classes = []\n",
        "for class_id, count in combined_class_counts.items():\n",
        "    if count < average_combined_instance_count:\n",
        "        new_minority_classes.append(class_names[class_id])\n",
        "\n",
        "if not new_minority_classes:\n",
        "    print(\"All classes are now above or very close to the average instance count, indicating improved balance.\")\n",
        "else:\n",
        "    print(f\"Classes still below the new average: {new_minority_classes}\")\n",
        "    print(\"Further augmentation might be beneficial for these classes.\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing augmented labels from: ./trash-detection/Dataset/labels/augmented_train\n",
            "Found 1653 augmented label files.\n",
            "\n",
            "Total instances added from augmented data: 5736\n",
            "\n",
            "--- Combined Dataset Class Analysis (Original + Augmented) ---\n",
            "Total instances (bounding boxes detected) in combined dataset: 13636\n",
            "Combined Class distribution:\n",
            "  - dirt (ID 0): 5672 instances\n",
            "  - liquid (ID 1): 1976 instances\n",
            "  - marks (ID 2): 3373 instances\n",
            "  - trash (ID 3): 2615 instances\n",
            "\n",
            "--- Class Balance Improvement Summary ---\n",
            "Original training class distribution:\n",
            "  - dirt (ID 0): 1418 instances\n",
            "  - liquid (ID 1): 494 instances\n",
            "  - marks (ID 2): 3373 instances\n",
            "  - trash (ID 3): 2615 instances\n",
            "\n",
            "Average instance count per class in original training set: 1975.00\n",
            "Average instance count per class in combined dataset: 3409.00\n",
            "Classes still below the new average: ['liquid', 'marks', 'trash']\n",
            "Further augmentation might be beneficial for these classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcab30bc"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "1.  **Which classes were targeted for augmentation?**\n",
        "    The minority classes targeted for augmentation were 'dirt' and 'liquid', as their initial instance counts (1418 and 494 respectively) were below the average instance count of 1975.00 across all classes in the original training set.\n",
        "2.  **Did the data augmentation process improve dataset balance?**\n",
        "    Yes, the data augmentation process significantly improved the dataset balance for the targeted minority classes, though not for non-targeted majority classes. The 'dirt' class increased from 1418 to 5672 instances, and the 'liquid' class increased from 494 to 1976 instances. The overall average instance count per class rose from 1975.00 to 3409.00. However, 'liquid', 'marks', and 'trash' classes still remain below the new average, indicating room for further improvement.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   Initially, the training dataset contained a total of 7900 instances across 4 classes, with an average of 1975.00 instances per class.\n",
        "*   The minority classes identified for augmentation were 'dirt' (1418 instances) and 'liquid' (494 instances), as they fell below the initial average.\n",
        "*   The data augmentation process applied the following transformations to images containing these minority classes:\n",
        "    *   Horizontal Flip\n",
        "    *   90-degree Clockwise Rotation\n",
        "    *   Brightness Adjustment (random factor between 0.7 and 1.3)\n",
        "*   A total of 1653 augmented images and their corresponding label files were generated. After refining the augmentation to only include minority class bounding boxes, 5736 new bounding box instances were added from the augmented data.\n",
        "*   After augmentation, the combined dataset consists of 13636 instances, with an increased average of 3409.00 instances per class.\n",
        "*   The class distribution after refined augmentation:\n",
        "    *   **dirt**: Increased from 1418 to 5672 instances.\n",
        "    *   **liquid**: Increased from 494 to 1976 instances.\n",
        "    *   **marks**: Remained at 3373 instances (as these were not minority classes and their bounding boxes were excluded from augmented labels).\n",
        "    *   **trash**: Remained at 2615 instances (as these were not minority classes and their bounding boxes were excluded from augmented labels).\n",
        "*   Despite the significant improvements for targeted classes, the 'liquid' (1976 instances), 'marks' (3373 instances), and 'trash' (2615 instances) classes are still below the new average instance count of 3409.00.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The refined data augmentation successfully boosted the representation of the 'dirt' and 'liquid' classes by only augmenting their bounding boxes, leading to a more focused balancing approach. This is crucial for improving the performance of object detection models, especially for underrepresented categories.\n",
        "*   The 'marks' and 'trash' classes were not directly augmented, leading to them now being below the new average. To achieve even greater balance, consider applying further targeted augmentation strategies specifically for 'liquid', 'marks', and 'trash' classes, perhaps using more aggressive augmentation policies or generating more augmented samples for these particular classes. Alternatively, the strategy could be adjusted to augment all bounding boxes in an image if any minority class is present, if the goal is general dataset expansion rather than strict class-specific balancing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f4bec56"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Provide a comprehensive summary of the refined data augmentation process, including the types of augmentations applied, the classes targeted, and the resulting class distribution, highlighting how the dataset balance has been improved.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75c2a550"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "1.  **Which classes were targeted for augmentation?**\n",
        "    The minority classes targeted for augmentation were 'dirt' and 'liquid'. Initially, their instance counts were 1418 and 494, respectively, which were below the original average instance count of 1975.00 per class across the dataset.\n",
        "2.  **Did the data augmentation process improve dataset balance?**\n",
        "    Yes, the data augmentation process significantly improved the dataset balance for the targeted minority classes. The 'dirt' class increased from 1418 to 5672 instances, and the 'liquid' class increased from 494 to 1976 instances. The overall average instance count per class rose from 1975.00 to 3409.00. However, 'liquid', 'marks', and 'trash' classes still remain below this new average, indicating further scope for improvement.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The original training dataset contained a total of 7900 instances across 4 classes, with an average of 1975.00 instances per class.\n",
        "*   The minority classes identified and targeted for augmentation were 'dirt' (1418 instances) and 'liquid' (494 instances).\n",
        "*   The data augmentation process applied the following transformations to images containing instances of these minority classes: Horizontal Flip, 90-degree Clockwise Rotation, and Brightness Adjustment (random factor between 0.7 and 1.3).\n",
        "*   A total of 1653 augmented images and their corresponding label files were generated. The refined logic ensured that only bounding boxes belonging to the minority classes were saved in the augmented label files, adding 5736 new bounding box instances.\n",
        "*   After augmentation, the combined dataset now contains 13636 instances, and the average instance count per class increased to 3409.00.\n",
        "*   The class distribution after the refined augmentation is as follows:\n",
        "    *   **dirt**: Increased substantially from 1418 to 5672 instances.\n",
        "    *   **liquid**: Increased from 494 to 1976 instances.\n",
        "    *   **marks**: Remained at 3373 instances (as it was not a targeted minority class and its bounding boxes were excluded from augmentation).\n",
        "    *   **trash**: Remained at 2615 instances (as it was not a targeted minority class and its bounding boxes were excluded from augmentation).\n",
        "*   Despite improvements for 'dirt' and 'liquid', the classes 'liquid' (1976 instances), 'marks' (3373 instances), and 'trash' (2615 instances) are still below the new average instance count of 3409.00.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The refined data augmentation strategy successfully focused on increasing the representation of 'dirt' and 'liquid' by exclusively augmenting their bounding boxes, which is a targeted and effective approach for balancing minority classes in object detection.\n",
        "*   To achieve a more uniform distribution across all classes, further targeted augmentation should be considered for 'liquid', 'marks', and 'trash' classes, which are still below the new average instance count. This could involve generating more augmented samples for these specific classes or employing more aggressive augmentation techniques.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O22IAnwyyzKm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc4c2af7"
      },
      "source": [
        "# Task\n",
        "Identify all image files and their corresponding YOLO label files in the `trash-detection/Dataset/images/val` and `trash-detection/Dataset/labels/val` directories. Then, create a mapping where each image file path is associated with its respective label file path."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba7386cb"
      },
      "source": [
        "## Identify Validation Images and Labels\n",
        "\n",
        "### Subtask:\n",
        "List all image files and their corresponding YOLO label files in the existing `trash-detection/Dataset/images/val` and `trash-detection/Dataset/labels/val` directories. Create a mapping of image file paths to label file paths to prepare for splitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fd0a8d8"
      },
      "source": [
        "**Reasoning**:\n",
        "I will define the paths for the validation image and label directories, then iterate through the image files to create a mapping to their corresponding label files, verifying their existence, and finally print a summary of the mapping.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd1a81c5",
        "outputId": "cf1c1586-cb8c-487c-dde4-43e4df6d967b"
      },
      "source": [
        "import os\n",
        "\n",
        "# 1. Define the paths for the original validation images and labels directories\n",
        "original_val_images_dir = './trash-detection/Dataset/images/val'\n",
        "original_val_labels_dir = './trash-detection/Dataset/labels/val'\n",
        "\n",
        "# 2. Initialize an empty dictionary to store the mapping\n",
        "validation_data_map = {}\n",
        "\n",
        "# Define common image formats\n",
        "image_formats = ('.jpg', '.jpeg', '.png')\n",
        "\n",
        "# 3. List all files in the original validation images directory and filter for image files\n",
        "image_files = [f for f in os.listdir(original_val_images_dir) if f.lower().endswith(image_formats)]\n",
        "\n",
        "print(f\"Found {len(image_files)} potential image files in {original_val_images_dir}\")\n",
        "\n",
        "# 4. & 5. For each image file, construct its full path and derive the corresponding label file path\n",
        "for img_filename in image_files:\n",
        "    img_filepath = os.path.join(original_val_images_dir, img_filename)\n",
        "\n",
        "    # Derive label filename by changing extension to .txt\n",
        "    base_filename, _ = os.path.splitext(img_filename)\n",
        "    label_filename = base_filename + '.txt'\n",
        "    label_filepath = os.path.join(original_val_labels_dir, label_filename)\n",
        "\n",
        "    # 6. Check if both the image file and its corresponding label file exist\n",
        "    if os.path.exists(img_filepath) and os.path.exists(label_filepath):\n",
        "        validation_data_map[img_filepath] = label_filepath\n",
        "\n",
        "# 7. Print the total number of image-label pairs found and a few examples\n",
        "print(f\"\\nTotal image-label pairs found for validation: {len(validation_data_map)}\")\n",
        "\n",
        "print(\"\\nExamples of image-label mapping:\")\n",
        "count = 0\n",
        "for img_path, label_path in validation_data_map.items():\n",
        "    if count < 5: # Print first 5 examples\n",
        "        print(f\"  Image: {img_path}\\n  Label: {label_path}\")\n",
        "        count += 1\n",
        "    else:\n",
        "        break\n",
        "\n",
        "if not validation_data_map:\n",
        "    print(\"No image-label pairs were found. Please check directory paths and file formats.\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 308 potential image files in ./trash-detection/Dataset/images/val\n",
            "\n",
            "Total image-label pairs found for validation: 308\n",
            "\n",
            "Examples of image-label mapping:\n",
            "  Image: ./trash-detection/Dataset/images/val/445.jpg\n",
            "  Label: ./trash-detection/Dataset/labels/val/445.txt\n",
            "  Image: ./trash-detection/Dataset/images/val/batch15_000011.jpg\n",
            "  Label: ./trash-detection/Dataset/labels/val/batch15_000011.txt\n",
            "  Image: ./trash-detection/Dataset/images/val/batch1_000019.jpg\n",
            "  Label: ./trash-detection/Dataset/labels/val/batch1_000019.txt\n",
            "  Image: ./trash-detection/Dataset/images/val/batch3_IMG_4992.JPG\n",
            "  Label: ./trash-detection/Dataset/labels/val/batch3_IMG_4992.txt\n",
            "  Image: ./trash-detection/Dataset/images/val/733.jpg\n",
            "  Label: ./trash-detection/Dataset/labels/val/733.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b76fa6f"
      },
      "source": [
        "## Perform Non-Stratified Split (70% Test, 30% Val)\n",
        "\n",
        "### Subtask:\n",
        "Implement a Python function to split the identified image-label pairs into a 70% subset for the new test set and a 30% subset for the new validation set. This split will be non-stratified and will use a random seed of 42 for reproducibility.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d03fe7b"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to import `train_test_split` from `sklearn.model_selection` to perform the dataset splitting as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a6ba254",
        "outputId": "7eb8ea0e-611c-49b1-d968-14e7313bc089"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"Imported train_test_split from sklearn.model_selection.\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imported train_test_split from sklearn.model_selection.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd32fca4"
      },
      "source": [
        "**Reasoning**:\n",
        "I will convert the `validation_data_map` into a list of tuples and then use `train_test_split` to divide it into a 70% test set and a 30% new validation set, using `random_state=42` for reproducibility, and finally print the counts of each split.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "750b8df9",
        "outputId": "aeb3406b-a26e-4f0e-8042-1077476df2bc"
      },
      "source": [
        "import random\n",
        "\n",
        "# 1. Convert the validation_data_map dictionary into a list of (image_path, label_path) tuples.\n",
        "validation_items = list(validation_data_map.items())\n",
        "\n",
        "# 2. & 3. Use train_test_split to divide the list of tuples\n",
        "# The split is 70% for test and 30% for new validation. We'll use train_size=0.3 for the new_val_set_map\n",
        "# and the remaining 0.7 will be for the test_set_map.\n",
        "new_val_set_map, test_set_map = train_test_split(\n",
        "    validation_items,\n",
        "    test_size=0.7,\n",
        "    random_state=42,\n",
        "    shuffle=True # Ensure shuffling is applied before splitting\n",
        ")\n",
        "\n",
        "# 5. Print the number of items in test_set_map and new_val_set_map to verify the split proportions.\n",
        "print(f\"Total original validation items: {len(validation_items)}\")\n",
        "print(f\"Number of items in the new validation set (30%): {len(new_val_set_map)}\")\n",
        "print(f\"Number of items in the new test set (70%): {len(test_set_map)}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total original validation items: 308\n",
            "Number of items in the new validation set (30%): 92\n",
            "Number of items in the new test set (70%): 216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "360f2b75"
      },
      "source": [
        "## Create New Directory Structure\n",
        "\n",
        "### Subtask:\n",
        "Create the necessary new directories for the `test` set (e.g., `trash-detection/Dataset/images/test` and `trash-detection/Dataset/labels/test`) and the `new_val` set (e.g., `trash-detection/Dataset/images/new_val` and `trash-detection/Dataset/labels/new_val`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc9b0621"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to define the paths for the new test and new validation directories and then create them using `os.makedirs` to prepare the directory structure for the split data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "191bd3ce",
        "outputId": "10c17db7-4d85-4157-fb96-c1aaa8723333"
      },
      "source": [
        "import os\n",
        "\n",
        "# 1. Define the base directory paths for the new test and new validation sets\n",
        "new_test_images_dir = './trash-detection/Dataset/images/test'\n",
        "new_test_labels_dir = './trash-detection/Dataset/labels/test'\n",
        "\n",
        "new_val_images_dir = './trash-detection/Dataset/images/new_val'\n",
        "new_val_labels_dir = './trash-detection/Dataset/labels/new_val'\n",
        "\n",
        "# 2. Create these new directories\n",
        "os.makedirs(new_test_images_dir, exist_ok=True)\n",
        "os.makedirs(new_test_labels_dir, exist_ok=True)\n",
        "os.makedirs(new_val_images_dir, exist_ok=True)\n",
        "os.makedirs(new_val_labels_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Created directory: {new_test_images_dir}\")\n",
        "print(f\"Created directory: {new_test_labels_dir}\")\n",
        "print(f\"Created directory: {new_val_images_dir}\")\n",
        "print(f\"Created directory: {new_val_labels_dir}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created directory: ./trash-detection/Dataset/images/test\n",
            "Created directory: ./trash-detection/Dataset/labels/test\n",
            "Created directory: ./trash-detection/Dataset/images/new_val\n",
            "Created directory: ./trash-detection/Dataset/labels/new_val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3241da4a"
      },
      "source": [
        "## Move Files to New Test and Validation Directories\n",
        "\n",
        "### Subtask:\n",
        "Based on the results of the non-stratified split (70% test, 30% new validation), move the actual image and corresponding label files from the original validation directory to their respective newly designated `test` and `new_val` directories.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7d08920"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to import the `shutil` module to perform file copy operations, then iterate through `test_set_map` and `new_val_set_map` to copy image and label files to their respective new directories as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fe8484d",
        "outputId": "06950a0a-c247-4609-f152-49157d104ae6"
      },
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Initialize counters for moved files\n",
        "test_images_moved = 0\n",
        "test_labels_moved = 0\n",
        "new_val_images_moved = 0\n",
        "new_val_labels_moved = 0\n",
        "\n",
        "# 1. Move files to the new test set directories\n",
        "print(f\"\\nMoving files to test directories: {new_test_images_dir} and {new_test_labels_dir}\")\n",
        "for img_path, label_path in test_set_map:\n",
        "    # Extract base filename and extension\n",
        "    base_filename = os.path.splitext(os.path.basename(img_path))[0]\n",
        "    img_extension = os.path.splitext(img_path)[1]\n",
        "\n",
        "    # Construct destination paths for test set\n",
        "    dest_img_path = os.path.join(new_test_images_dir, base_filename + img_extension)\n",
        "    dest_label_path = os.path.join(new_test_labels_dir, base_filename + '.txt')\n",
        "\n",
        "    # Copy image and label files\n",
        "    shutil.copy(img_path, dest_img_path)\n",
        "    shutil.copy(label_path, dest_label_path)\n",
        "\n",
        "    test_images_moved += 1\n",
        "    test_labels_moved += 1\n",
        "\n",
        "# 2. Move files to the new validation set directories\n",
        "print(f\"Moving files to new validation directories: {new_val_images_dir} and {new_val_labels_dir}\")\n",
        "for img_path, label_path in new_val_set_map:\n",
        "    # Extract base filename and extension\n",
        "    base_filename = os.path.splitext(os.path.basename(img_path))[0]\n",
        "    img_extension = os.path.splitext(img_path)[1]\n",
        "\n",
        "    # Construct destination paths for new validation set\n",
        "    dest_img_path = os.path.join(new_val_images_dir, base_filename + img_extension)\n",
        "    dest_label_path = os.path.join(new_val_labels_dir, base_filename + '.txt')\n",
        "\n",
        "    # Copy image and label files\n",
        "    shutil.copy(img_path, dest_img_path)\n",
        "    shutil.copy(label_path, dest_label_path)\n",
        "\n",
        "    new_val_images_moved += 1\n",
        "    new_val_labels_moved += 1\n",
        "\n",
        "# 3. Print confirmation message\n",
        "print(\"\\nFile moving complete!\")\n",
        "print(f\"  - Total images moved to test directory: {test_images_moved}\")\n",
        "print(f\"  - Total labels moved to test directory: {test_labels_moved}\")\n",
        "print(f\"  - Total images moved to new validation directory: {new_val_images_moved}\")\n",
        "print(f\"  - Total labels moved to new validation directory: {new_val_labels_moved}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Moving files to test directories: ./trash-detection/Dataset/images/test and ./trash-detection/Dataset/labels/test\n",
            "Moving files to new validation directories: ./trash-detection/Dataset/images/new_val and ./trash-detection/Dataset/labels/new_val\n",
            "\n",
            "File moving complete!\n",
            "  - Total images moved to test directory: 216\n",
            "  - Total labels moved to test directory: 216\n",
            "  - Total images moved to new validation directory: 92\n",
            "  - Total labels moved to new validation directory: 92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "560681bf"
      },
      "source": [
        "## Verify Split Sizes of New Test and Validation Sets\n",
        "\n",
        "### Subtask:\n",
        "Recalculate and display the total number of files in the newly created test set (70%) and the new validation set (30%). This step will confirm that the split has been executed according to the specified proportions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e398a110"
      },
      "source": [
        "**Reasoning**:\n",
        "I will import the `os` module and then count and print the number of files in the newly created test and validation image directories to verify the split.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5765fc2b",
        "outputId": "14a0f781-a3f1-46fc-a658-00839906e503"
      },
      "source": [
        "import os\n",
        "\n",
        "# Define the paths for the new test and new validation images directories\n",
        "# These variables are already defined in previous cells but are re-defined for clarity if this cell were run independently.\n",
        "new_test_images_dir = './trash-detection/Dataset/images/test'\n",
        "new_val_images_dir = './trash-detection/Dataset/images/new_val'\n",
        "\n",
        "# Count the number of files in each directory\n",
        "num_test_images = len(os.listdir(new_test_images_dir))\n",
        "num_new_val_images = len(os.listdir(new_val_images_dir))\n",
        "\n",
        "# Print the results\n",
        "print(f\"Number of images in the new test set directory ({new_test_images_dir}): {num_test_images}\")\n",
        "print(f\"Number of images in the new validation set directory ({new_val_images_dir}): {num_new_val_images}\")\n",
        "\n",
        "# Verify against expected counts (from previous split output)\n",
        "print(\"Expected test images: 216\")\n",
        "print(\"Expected new validation images: 92\")\n",
        "\n",
        "if num_test_images == 216 and num_new_val_images == 92:\n",
        "    print(\"File counts match the expected split proportions.\")\n",
        "else:\n",
        "    print(\"Warning: File counts do not match expected split proportions.\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in the new test set directory (./trash-detection/Dataset/images/test): 216\n",
            "Number of images in the new validation set directory (./trash-detection/Dataset/images/new_val): 92\n",
            "Expected test images: 216\n",
            "Expected new validation images: 92\n",
            "File counts match the expected split proportions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfe58c55"
      },
      "source": [
        "## Update data.yaml Configuration\n",
        "\n",
        "### Subtask:\n",
        "Modify the `trash-detection/Dataset/data.yaml` file to reflect the new dataset organization. This includes adding the path for the new `test` set and updating the `val` path to point to the newly created 30% validation split.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5876834b"
      },
      "source": [
        "**Reasoning**:\n",
        "I will construct the full path to `data.yaml`, open and parse it, then update the `train` and `val` paths and add a new `test` path to reflect the new dataset organization. Finally, I will write the modified content back to the file and display its updated contents.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6ffda36",
        "outputId": "bd92c4b7-d4a5-4eda-8d91-920497487a53"
      },
      "source": [
        "import yaml\n",
        "import os\n",
        "\n",
        "# 1. Construct the full path to the data.yaml file\n",
        "data_yaml_path = 'trash-detection/Dataset/data.yaml'\n",
        "\n",
        "# 2. Open and parse the data.yaml file\n",
        "with open(data_yaml_path, 'r') as file:\n",
        "    data = yaml.safe_load(file)\n",
        "\n",
        "# 3. Update the 'train' key to 'images/train'\n",
        "# The original 'train' value might be an absolute path or a different relative path.\n",
        "# We need to ensure it points to the correct relative path from the Dataset directory.\n",
        "# Based on the structure, it should be 'images/train'\n",
        "data['train'] = 'images/train'\n",
        "\n",
        "# 4. Update the 'val' path to point to the newly created 30% validation split ('images/new_val')\n",
        "data['val'] = 'images/new_val'\n",
        "\n",
        "# 5. Add a new key 'test' with the value 'images/test'\n",
        "data['test'] = 'images/test'\n",
        "\n",
        "# 6. Write the modified data dictionary back to the data.yaml file\n",
        "with open(data_yaml_path, 'w') as file:\n",
        "    yaml.dump(data, file, default_flow_style=False)\n",
        "\n",
        "# 7. Print a confirmation message and display the new contents of the data.yaml file\n",
        "print(f\"Successfully updated {data_yaml_path}.\\n\")\n",
        "print(\"New data.yaml content:\")\n",
        "with open(data_yaml_path, 'r') as file:\n",
        "    print(file.read())\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully updated trash-detection/Dataset/data.yaml.\n",
            "\n",
            "New data.yaml content:\n",
            "names:\n",
            "- dirt\n",
            "- liquid\n",
            "- marks\n",
            "- trash\n",
            "nc: 4\n",
            "test: images/test\n",
            "train: images/train\n",
            "val: images/new_val\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8a8d332"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Provide a comprehensive summary of the process, detailing the new splitting proportion (70% test, 30% validation), the random seed used, and the verified sizes of the new test and validation sets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "107bf83e"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   Initially, 308 image-label pairs were identified within the `trash-detection/Dataset/images/val` and `trash-detection/Dataset/labels/val` directories.\n",
        "*   These 308 pairs were split using a non-stratified method with `random_state=42`:\n",
        "    *   A new test set was created with 216 image-label pairs, representing approximately 70% of the original validation data.\n",
        "    *   A new validation set was created with 92 image-label pairs, representing approximately 30% of the original validation data.\n",
        "*   New directories were successfully created for both the test (`./trash-detection/Dataset/images/test`, `./trash-detection/Dataset/labels/test`) and new validation (`./trash-detection/Dataset/images/new_val`, `./trash-detection/Dataset/labels/new_val`) sets.\n",
        "*   All 216 image and 216 label files were copied to the new test directories, and all 92 image and 92 label files were copied to the new validation directories.\n",
        "*   Verification confirmed that the new test set contains 216 images and the new validation set contains 92 images, aligning precisely with the specified 70% and 30% proportions.\n",
        "*   The `trash-detection/Dataset/data.yaml` file was updated to reflect the new dataset organization, setting `train: images/train`, `val: images/new_val`, and introducing `test: images/test`.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The dataset has been successfully re-organized into a 70% test and 30% validation split from the original validation set, with proper directory structure and `data.yaml` configuration for YOLO-compatible training.\n",
        "*   Proceed with model training and evaluation using the newly defined test and validation sets to ensure robust performance assessment based on the updated data splits.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66f2dcef"
      },
      "source": [
        "# Task\n",
        "To provide a comprehensive summary of the current state of the dataset, I will develop and execute Python code to count the number of image/label files and the total number of instances (bounding boxes) for the training set, the new validation set, and the new test set. This will involve iterating through the respective directories and parsing label files. Finally, I will display a clear summary table showing the total number of files and total instances for each set.\n",
        "\n",
        "Here's the plan:\n",
        "*   **Count Files and Instances for Each Set**: Develop and execute Python code to count the number of image/label files and the total number of instances (bounding boxes) for the training set, the new validation set, and the new test set. This will involve iterating through the respective directories and parsing label files.\n",
        "*   **Present Summary of Dataset Counts**: Display a clear summary table or printout showing the total number of files and total instances for the training, new validation, and new test sets, based on the counts obtained in the previous step.\n",
        "*   **Final Task**: Provide a comprehensive summary of the current state of the dataset, including the file and instance counts for each split."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d664a28"
      },
      "source": [
        "## Count Files and Instances for Each Set\n",
        "\n",
        "### Subtask:\n",
        "Develop and execute Python code to count the number of image/label files and the total number of instances (bounding boxes) for the training set, the new validation set, and the new test set. This will involve iterating through the respective directories and parsing label files.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d367f09d"
      },
      "source": [
        "**Reasoning**:\n",
        "I will define the paths for the training, new validation, and new test sets, then iterate through their respective image and label directories to count files and bounding box instances, storing these statistics in a dictionary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9945f2b8",
        "outputId": "9c246dcf-03bf-4ef3-d739-0dc377f66b63"
      },
      "source": [
        "import os\n",
        "\n",
        "# 1. Define the base paths for images and labels for each set\n",
        "# Training set (original + augmented)\n",
        "original_train_images_dir = './trash-detection/Dataset/images/train'\n",
        "original_train_labels_dir = './trash-detection/Dataset/labels/train'\n",
        "augmented_train_images_dir = './trash-detection/Dataset/images/augmented_train'\n",
        "augmented_train_labels_dir = './trash-detection/Dataset/labels/augmented_train'\n",
        "\n",
        "# New Validation set\n",
        "new_val_images_dir = './trash-detection/Dataset/images/new_val'\n",
        "new_val_labels_dir = './trash-detection/Dataset/labels/new_val'\n",
        "\n",
        "# New Test set\n",
        "new_test_images_dir = './trash-detection/Dataset/images/test'\n",
        "new_test_labels_dir = './trash-detection/Dataset/labels/test'\n",
        "\n",
        "# Define common image formats\n",
        "image_formats = ('.jpg', '.jpeg', '.png', '.JPG')\n",
        "\n",
        "# 2. Initialize an empty dictionary to store statistics\n",
        "dataset_stats = {\n",
        "    'train': {'images': 0, 'labels': 0, 'instances': 0},\n",
        "    'new_val': {'images': 0, 'labels': 0, 'instances': 0},\n",
        "    'test': {'images': 0, 'labels': 0, 'instances': 0}\n",
        "}\n",
        "\n",
        "# Helper function to count files and instances in a directory\n",
        "def count_files_and_instances(image_dir, label_dir):\n",
        "    num_images = 0\n",
        "    num_labels = 0\n",
        "    num_instances = 0\n",
        "\n",
        "    # Count image files\n",
        "    if os.path.exists(image_dir):\n",
        "        num_images = len([f for f in os.listdir(image_dir) if f.lower().endswith(image_formats)])\n",
        "\n",
        "    # Count label files and instances\n",
        "    if os.path.exists(label_dir):\n",
        "        label_files = [f for f in os.listdir(label_dir) if f.endswith('.txt')]\n",
        "        num_labels = len(label_files)\n",
        "        for filename in label_files:\n",
        "            filepath = os.path.join(label_dir, filename)\n",
        "            try:\n",
        "                with open(filepath, 'r') as f:\n",
        "                    for line in f:\n",
        "                        if line.strip(): # Count non-empty lines as instances\n",
        "                            num_instances += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Could not read label file {filepath}: {e}\")\n",
        "\n",
        "    return num_images, num_labels, num_instances\n",
        "\n",
        "# 3. Process each dataset split\n",
        "\n",
        "# --- Training Set ---\n",
        "# Original training data\n",
        "train_orig_images, train_orig_labels, train_orig_instances = count_files_and_instances(original_train_images_dir, original_train_labels_dir)\n",
        "dataset_stats['train']['images'] += train_orig_images\n",
        "dataset_stats['train']['labels'] += train_orig_labels\n",
        "dataset_stats['train']['instances'] += train_orig_instances\n",
        "\n",
        "# Augmented training data\n",
        "train_aug_images, train_aug_labels, train_aug_instances = count_files_and_instances(augmented_train_images_dir, augmented_train_labels_dir)\n",
        "dataset_stats['train']['images'] += train_aug_images\n",
        "dataset_stats['train']['labels'] += train_aug_labels\n",
        "dataset_stats['train']['instances'] += train_aug_instances\n",
        "\n",
        "# --- New Validation Set ---\n",
        "new_val_images, new_val_labels, new_val_instances = count_files_and_instances(new_val_images_dir, new_val_labels_dir)\n",
        "dataset_stats['new_val']['images'] = new_val_images\n",
        "dataset_stats['new_val']['labels'] = new_val_labels\n",
        "dataset_stats['new_val']['instances'] = new_val_instances\n",
        "\n",
        "# --- New Test Set ---\n",
        "test_images, test_labels, test_instances = count_files_and_instances(new_test_images_dir, new_test_labels_dir)\n",
        "dataset_stats['test']['images'] = test_images\n",
        "dataset_stats['test']['labels'] = test_labels\n",
        "dataset_stats['test']['instances'] = test_instances\n",
        "\n",
        "# Print the results\n",
        "print(\"\\n--- Dataset Statistics ---\")\n",
        "for split, stats in dataset_stats.items():\n",
        "    print(f\"\\n{split.replace('_', ' ').capitalize()} Set:\")\n",
        "    print(f\"  Images: {stats['images']}\")\n",
        "    print(f\"  Labels: {stats['labels']}\")\n",
        "    print(f\"  Instances (bounding boxes): {stats['instances']}\")\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Dataset Statistics ---\n",
            "\n",
            "Train Set:\n",
            "  Images: 2882\n",
            "  Labels: 2882\n",
            "  Instances (bounding boxes): 13636\n",
            "\n",
            "New val Set:\n",
            "  Images: 92\n",
            "  Labels: 92\n",
            "  Instances (bounding boxes): 651\n",
            "\n",
            "Test Set:\n",
            "  Images: 216\n",
            "  Labels: 216\n",
            "  Instances (bounding boxes): 1367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dd10288"
      },
      "source": [
        "## Final Dataset Summary\n",
        "\n",
        "This summary provides an overview of the `trash-detection` dataset after data augmentation and the new train/validation/test split.\n",
        "\n",
        "### Overall Dataset Structure:\n",
        "\n",
        "The dataset is now organized into three main splits:\n",
        "- **Training Set**: Comprising both original training data and augmented data for minority classes.\n",
        "- **New Validation Set**: A 30% split from the original validation data.\n",
        "- **New Test Set**: A 70% split from the original validation data.\n",
        "\n",
        "### Dataset Statistics:\n",
        "\n",
        "| Dataset Split    | Images | Labels | Instances (Bounding Boxes) |\n",
        "| :--------------- | :----- | :----- | :------------------------- |\n",
        "| **Training Set** | 2882   | 2882   | 13636                      |\n",
        "| **New Validation Set** | 92     | 92     | 651                        |\n",
        "| **New Test Set** | 216    | 216    | 1367                       |\n",
        "\n",
        "### Key Findings:\n",
        "\n",
        "*   **Training Set Growth**: The training set has been significantly expanded through data augmentation, increasing the total number of images and instances available for model training. This includes both the original 1229 training images and 1653 augmented images.\n",
        "*   **Balanced Splits**: The new validation and test sets were created by splitting the original validation set (308 image-label pairs) into a 30% new validation set (92 images) and a 70% new test set (216 images), ensuring a clear separation for model evaluation.\n",
        "*   **Instance Distribution**: The instance counts reflect the bounding boxes present across all images in each set. The training set, with its augmented data, now has a substantial number of instances, which should aid in improving model robustness and performance, particularly for the previously underrepresented classes ('dirt' and 'liquid').\n",
        "\n",
        "### Conclusion:\n",
        "\n",
        "The dataset is now prepared with a comprehensive training set (including augmented data), a dedicated validation set for hyperparameter tuning, and a separate test set for final model evaluation. This structure ensures a robust and representative dataset for developing and assessing an object detection model for trash detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32fb0d32"
      },
      "source": [
        "## Present Summary of Dataset Counts\n",
        "\n",
        "### Subtask:\n",
        "Display a clear summary table or printout showing the total number of files and total instances for the training, new validation, and new test sets, based on the counts obtained in the previous step.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f53f14d"
      },
      "source": [
        "## Dataset Statistics Summary\n",
        "\n",
        "| Dataset Split | Images | Labels | Instances (bounding boxes) |\n",
        "|---------------|--------|--------|----------------------------|\n",
        "| Train         | 2882   | 2882   | 13636                      |\n",
        "| New Validation| 92     | 92     | 651                        |\n",
        "| Test          | 216    | 216    | 1367                       |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe3e8f6f"
      },
      "source": [
        "## Dataset Statistics Summary\n",
        "\n",
        "| Dataset Split | Images | Labels | Instances (bounding boxes) |\n",
        "|---------------|--------|--------|----------------------------|\n",
        "| Train         | 2882   | 2882   | 13636                      |\n",
        "| New Validation| 92     | 92     | 651                        |\n",
        "| Test          | 216    | 216    | 1367                       |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6c2a7cf"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Provide a comprehensive summary of the current state of the dataset, including the file and instance counts for each split.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf27de59"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The **Training Set** comprises 2882 images, 2882 label files, and a total of 13636 instances (bounding boxes). This includes both original training data and augmented data.\n",
        "*   The **New Validation Set** consists of 92 images, 92 label files, and 651 instances. This set was created by taking a 30% split from the original validation data.\n",
        "*   The **New Test Set** contains 216 images, 216 label files, and 1367 instances. This set was formed from the remaining 70% of the original validation data.\n",
        "*   The data augmentation process significantly expanded the training set, contributing to a substantial increase in both images and bounding box instances available for model training.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The dataset is now well-structured with dedicated training, validation, and test splits, including augmented data in the training set, which is crucial for robust object detection model development and evaluation.\n",
        "*   The balanced distribution of instances across the validation and test sets, derived from the original validation data, provides a consistent basis for assessing model performance before and after training.\n"
      ]
    }
  ]
}