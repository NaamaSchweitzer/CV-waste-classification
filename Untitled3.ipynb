{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNnEvynd8A4hIIhUaPwIVNl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NaamaSchweitzer/CV-waste-classification/blob/ModelProcessing/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6R-jtxnnNUe",
        "outputId": "d09962aa-c333-4f5c-8b26-e1c7885f8c25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-29 12:45:05--  https://raw.githubusercontent.com/NaamaSchweitzer/CV-waste-classification/Preprocessing/CV_Waste_Classification.ipynb\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 116592 (114K) [text/plain]\n",
            "Saving to: â€˜CV_Waste_Classification.ipynbâ€™\n",
            "\n",
            "\r          CV_Waste_   0%[                    ]       0  --.-KB/s               \rCV_Waste_Classifica 100%[===================>] 113.86K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-11-29 12:45:05 (10.9 MB/s) - â€˜CV_Waste_Classification.ipynbâ€™ saved [116592/116592]\n",
            "\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle) (0.5.1)\n",
            "cp: cannot stat 'kaggle.json': No such file or directory\n",
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Kaggle authentication setup complete.\n",
            "Dataset URL: https://www.kaggle.com/datasets/alyyan/trash-detection\n",
            "License(s): MIT\n",
            "Downloading trash-detection.zip to /content\n",
            "100% 1.23G/1.23G [00:16<00:00, 79.1MB/s]\n",
            "100% 1.23G/1.23G [00:16<00:00, 82.0MB/s]\n",
            "CV_Waste_Classification.ipynb  sample_data  trash-detection.zip\n",
            "Dataset\n",
            "Dataset downloaded and extracted successfully!\n",
            "data.yaml  images/  labels/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (6.0.3)\n",
            "PyYAML installed successfully.\n",
            "Dataset metadata loaded from: trash-detection/Dataset/data.yaml\n",
            "Detected classes (nc): 4\n",
            "Class names: ['dirt', 'liquid', 'marks', 'trash']\n",
            "Processing 1229 label files...\n",
            "\n",
            "--- Dataset Class Analysis ---\n",
            "Total instances (bounding boxes detected): 7900\n",
            "Class distribution:\n",
            "  - dirt (ID 0): 1418 instances\n",
            "  - liquid (ID 1): 494 instances\n",
            "  - marks (ID 2): 3373 instances\n",
            "  - trash (ID 3): 2615 instances\n",
            "Processing 308 label files...\n",
            "\n",
            "--- Dataset Class Analysis ---\n",
            "Total instances (bounding boxes detected): 2018\n",
            "Class distribution:\n",
            "  - dirt (ID 0): 367 instances\n",
            "  - liquid (ID 1): 140 instances\n",
            "  - marks (ID 2): 822 instances\n",
            "  - trash (ID 3): 689 instances\n",
            "Total instances in training set: 7900\n",
            "Number of classes: 4\n",
            "Average instance count per class: 1975.00\n",
            "Identified minority classes for augmentation: ['dirt', 'liquid']\n",
            "Created directory: ./trash-detection/Dataset/images/augmented_train\n",
            "Created directory: ./trash-detection/Dataset/labels/augmented_train\n",
            "Necessary libraries imported: os, numpy, PIL (Image, ImageEnhance), random.\n",
            "Utility functions 'read_yolo_labels' and 'write_yolo_labels' defined.\n",
            "Data augmentation functions (horizontal_flip, vertical_flip, rotate_90_clockwise, adjust_brightness) defined.\n",
            "Starting data augmentation for minority classes: ['dirt', 'liquid']\n",
            "Original images directory: ./trash-detection/Dataset/images/train\n",
            "Original labels directory: ./trash-detection/Dataset/labels/train\n",
            "Augmented images directory: ./trash-detection/Dataset/images/augmented_train\n",
            "Augmented labels directory: ./trash-detection/Dataset/labels/augmented_train\n",
            "Finished data augmentation. Total augmented images/labels generated: 1653\n",
            "Augmented data stored in: ./trash-detection/Dataset/images/augmented_train and ./trash-detection/Dataset/labels/augmented_train\n",
            "Processing augmented labels from: ./trash-detection/Dataset/labels/augmented_train\n",
            "Found 1653 augmented label files.\n",
            "\n",
            "Total instances added from augmented data: 14193\n",
            "\n",
            "--- Combined Dataset Class Analysis (Original + Augmented) ---\n",
            "Total instances (bounding boxes detected) in combined dataset: 22093\n",
            "Combined Class distribution:\n",
            "  - dirt (ID 0): 5672 instances\n",
            "  - liquid (ID 1): 1976 instances\n",
            "  - marks (ID 2): 11830 instances\n",
            "  - trash (ID 3): 2615 instances\n",
            "\n",
            "--- Class Balance Improvement Summary ---\n",
            "Original training class distribution:\n",
            "  - dirt (ID 0): 1418 instances\n",
            "  - liquid (ID 1): 494 instances\n",
            "  - marks (ID 2): 3373 instances\n",
            "  - trash (ID 3): 2615 instances\n",
            "\n",
            "Average instance count per class in original training set: 1975.00\n",
            "Average instance count per class in combined dataset: 5523.25\n",
            "Classes still below the new average: ['liquid', 'trash']\n",
            "Further augmentation might be beneficial for these classes.\n",
            "Starting data augmentation for minority classes: ['dirt', 'liquid']\n",
            "Original images directory: ./trash-detection/Dataset/images/train\n",
            "Original labels directory: ./trash-detection/Dataset/labels/train\n",
            "Augmented images directory: ./trash-detection/Dataset/images/augmented_train\n",
            "Augmented labels directory: ./trash-detection/Dataset/labels/augmented_train\n",
            "Finished data augmentation. Total augmented images/labels generated: 1653\n",
            "Augmented data stored in: ./trash-detection/Dataset/images/augmented_train and ./trash-detection/Dataset/labels/augmented_train\n",
            "Processing augmented labels from: ./trash-detection/Dataset/labels/augmented_train\n",
            "Found 1653 augmented label files.\n",
            "\n",
            "Total instances added from augmented data: 5736\n",
            "\n",
            "--- Combined Dataset Class Analysis (Original + Augmented) ---\n",
            "Total instances (bounding boxes detected) in combined dataset: 13636\n",
            "Combined Class distribution:\n",
            "  - dirt (ID 0): 5672 instances\n",
            "  - liquid (ID 1): 1976 instances\n",
            "  - marks (ID 2): 3373 instances\n",
            "  - trash (ID 3): 2615 instances\n",
            "\n",
            "--- Class Balance Improvement Summary ---\n",
            "Original training class distribution:\n",
            "  - dirt (ID 0): 1418 instances\n",
            "  - liquid (ID 1): 494 instances\n",
            "  - marks (ID 2): 3373 instances\n",
            "  - trash (ID 3): 2615 instances\n",
            "\n",
            "Average instance count per class in original training set: 1975.00\n",
            "Average instance count per class in combined dataset: 3409.00\n",
            "Classes still below the new average: ['liquid', 'marks', 'trash']\n",
            "Further augmentation might be beneficial for these classes.\n",
            "Found 308 potential image files in ./trash-detection/Dataset/images/val\n",
            "\n",
            "Total image-label pairs found for validation: 308\n",
            "\n",
            "Examples of image-label mapping:\n",
            "  Image: ./trash-detection/Dataset/images/val/782.jpg\n",
            "  Label: ./trash-detection/Dataset/labels/val/782.txt\n",
            "  Image: ./trash-detection/Dataset/images/val/683.jpg\n",
            "  Label: ./trash-detection/Dataset/labels/val/683.txt\n",
            "  Image: ./trash-detection/Dataset/images/val/batch10_000035.jpg\n",
            "  Label: ./trash-detection/Dataset/labels/val/batch10_000035.txt\n",
            "  Image: ./trash-detection/Dataset/images/val/731.jpg\n",
            "  Label: ./trash-detection/Dataset/labels/val/731.txt\n",
            "  Image: ./trash-detection/Dataset/images/val/912.jpg\n",
            "  Label: ./trash-detection/Dataset/labels/val/912.txt\n",
            "Imported train_test_split from sklearn.model_selection.\n",
            "Total original validation items: 308\n",
            "Number of items in the new validation set (30%): 92\n",
            "Number of items in the new test set (70%): 216\n",
            "Created directory: ./trash-detection/Dataset/images/test\n",
            "Created directory: ./trash-detection/Dataset/labels/test\n",
            "Created directory: ./trash-detection/Dataset/images/new_val\n",
            "Created directory: ./trash-detection/Dataset/labels/new_val\n",
            "\n",
            "Moving files to test directories: ./trash-detection/Dataset/images/test and ./trash-detection/Dataset/labels/test\n",
            "Moving files to new validation directories: ./trash-detection/Dataset/images/new_val and ./trash-detection/Dataset/labels/new_val\n",
            "\n",
            "File moving complete!\n",
            "  - Total images moved to test directory: 216\n",
            "  - Total labels moved to test directory: 216\n",
            "  - Total images moved to new validation directory: 92\n",
            "  - Total labels moved to new validation directory: 92\n",
            "Number of images in the new test set directory (./trash-detection/Dataset/images/test): 216\n",
            "Number of images in the new validation set directory (./trash-detection/Dataset/images/new_val): 92\n",
            "Expected test images: 216\n",
            "Expected new validation images: 92\n",
            "File counts match the expected split proportions.\n",
            "Successfully updated trash-detection/Dataset/data.yaml.\n",
            "\n",
            "New data.yaml content:\n",
            "names:\n",
            "- dirt\n",
            "- liquid\n",
            "- marks\n",
            "- trash\n",
            "nc: 4\n",
            "test: images/test\n",
            "train: images/train\n",
            "val: images/new_val\n",
            "\n",
            "\n",
            "--- Dataset Statistics ---\n",
            "\n",
            "Train Set:\n",
            "  Images: 2882\n",
            "  Labels: 2882\n",
            "  Instances (bounding boxes): 13636\n",
            "\n",
            "New val Set:\n",
            "  Images: 92\n",
            "  Labels: 92\n",
            "  Instances (bounding boxes): 591\n",
            "\n",
            "Test Set:\n",
            "  Images: 216\n",
            "  Labels: 216\n",
            "  Instances (bounding boxes): 1427\n"
          ]
        }
      ],
      "source": [
        "!wget -O CV_Waste_Classification.ipynb \\\n",
        "  https://raw.githubusercontent.com/NaamaSchweitzer/CV-waste-classification/Preprocessing/CV_Waste_Classification.ipynb\n",
        "\n",
        "%run CV_Waste_Classification.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nPKTibtn1zD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YOLOv8 (Ultralytics)\n"
      ],
      "metadata": {
        "id": "N5HdvYsInnc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "# ===== IMPORTANT: RUN THIS CELL FIRST =====\n",
        "import os\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Set the CORRECT path to data.yaml\n",
        "data_config_path = './trash-detection/Dataset/data.yaml'\n",
        "\n",
        "# Verify it exists\n",
        "if os.path.exists(data_config_path):\n",
        "    print(f\"âœ“ Data configuration found at {data_config_path}\")\n",
        "else:\n",
        "    print(f\"âœ— Error: data.yaml not found at {data_config_path}\")\n",
        "\n",
        "# Set model name\n",
        "model_name = 'yolov8n.pt'\n",
        "\n",
        "# Helper function\n",
        "def load_pretrained_model(name):\n",
        "    return YOLO(name)\n",
        "\n",
        "print(f\"âœ“ Model name set to: {model_name}\")\n",
        "print(f\"âœ“ data_config_path = {data_config_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnCzOmvvnrGM",
        "outputId": "620f2dd0-4e1d-4363-a37a-48bd9d20ec0f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.233)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.18)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "âœ“ Data configuration found at ./trash-detection/Dataset/data.yaml\n",
            "âœ“ Model name set to: yolov8n.pt\n",
            "âœ“ data_config_path = ./trash-detection/Dataset/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installation and Environment Setup\n",
        "Before we begin, we need to install the ultralytics library. This library provides all the tools needed for training, evaluating, and using YOLOv8 models. The following cell installs the library, imports the required modules, and checks the environment (including GPU detection)."
      ],
      "metadata": {
        "id": "ibT_OWwmpYSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, Image\n",
        "\n",
        "ultralytics.checks()\n",
        "\n",
        "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"Warning: GPU not detected. Training might be slow.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxGmJnhPo_xB",
        "outputId": "aba44d8d-c147-41b2-ff48-a011113d6d62"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 42.0/112.6 GB disk)\n",
            "\n",
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Selecting a Base Model (Pretrained Backbone)\n",
        "Model Selection and Transfer Learning\n",
        "I chose the YOLOv8n (Nano version) model as our pretrained backbone. This is a lightweight and efficient model pre-trained on the large COCO dataset. Loading these weights gives us a strong foundation for Transfer Learning. We also verify that the path to the data.yaml file is correct."
      ],
      "metadata": {
        "id": "0NTgITNOqDvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import yaml\n",
        "import kagglehub\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Step 1: Download dataset\n",
        "print(\"Downloading dataset...\")\n",
        "path = \"./trash-detection\"\n",
        "dataset_root = f\"{path}/Dataset\"\n",
        "print(f\"Dataset root: {dataset_root}\")\n",
        "\n",
        "# Step 2: Read and fix data.yaml\n",
        "original_yaml_path = f\"{dataset_root}/data.yaml\"\n",
        "print(f\"\\nOriginal data.yaml contents:\")\n",
        "with open(original_yaml_path, 'r') as f:\n",
        "    content = f.read()\n",
        "    print(content)\n",
        "\n",
        "# Step 4: Verify images exist\n",
        "train_path = f\"{dataset_root}/images/augmented_train\"\n",
        "val_path = f\"{dataset_root}/images/new_val\"\n",
        "test_path = f\"{dataset_root}/images/test\"\n",
        "print(f\"\\nVerifying paths:\")\n",
        "print(f\"  Train images exist: {os.path.exists(train_path)} ({len(os.listdir(train_path)) if os.path.exists(train_path) else 0} files)\")\n",
        "print(f\"  Val images exist: {os.path.exists(val_path)} ({len(os.listdir(val_path)) if os.path.exists(val_path) else 0} files)\")\n",
        "print(f\"  Train images exist: {os.path.exists(test_path)} ({len(os.listdir(test_path)) if os.path.exists(test_path) else 0} files)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwT-5I8YqFPY",
        "outputId": "d6989130-3710-4e40-da22-afcf10e6ad99"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n",
            "Dataset root: ./trash-detection/Dataset\n",
            "\n",
            "Original data.yaml contents:\n",
            "names:\n",
            "- dirt\n",
            "- liquid\n",
            "- marks\n",
            "- trash\n",
            "nc: 4\n",
            "test: images/test\n",
            "train: images/augmented_train\n",
            "val: images/new_val\n",
            "\n",
            "\n",
            "Verifying paths:\n",
            "  Train images exist: True (2882 files)\n",
            "  Val images exist: True (92 files)\n",
            "  Train images exist: True (216 files)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training - First Run (Fine-Tuning Run 1)\n",
        "Now we'll start the Fine-Tuning process. I decided to train for 30 epochs. In this run, we'll use the standard YOLOv8 parameters (including the default initial learning rate lr0 of 0.01). The results will be saved in a dedicated folder (YOLOv8n_Run1_DefaultLR) for comparison later. We use batch=-1 to allow the library to choose the optimal batch size for the available GPU memory"
      ],
      "metadata": {
        "id": "qwXAWY7Sq7Ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Train with corrected data.yaml\n",
        "EPOCHS = 50\n",
        "IMAGE_SIZE = 640\n",
        "PROJECT_NAME = 'runs/detect'\n",
        "RUN1_NAME = 'YOLOv8n_Run1_DefaultLR'\n",
        "\n",
        "print(f\"\\nStarting Training Run 1 ({RUN1_NAME}) for {EPOCHS} epochs...\")\n",
        "print(f\"Using data config: {original_yaml_path}\")\n",
        "\n",
        "yoloV8N = YOLO('yolov8n.pt')\n",
        "\n",
        "results_run1 = yoloV8N.train(\n",
        "    data=original_yaml_path,  # Use the corrected file\n",
        "    epochs=EPOCHS,\n",
        "    imgsz=IMAGE_SIZE,\n",
        "    patience=10,\n",
        "    batch=-1,\n",
        "    project=PROJECT_NAME,\n",
        "    name=RUN1_NAME\n",
        ")\n",
        "print(\"Training Run 1 finished successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1uoZfwOq9Oi",
        "outputId": "4885dcdd-d3de-4e71-f6c0-9b5961c1be98"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Training Run 1 (YOLOv8n_Run1_DefaultLR) for 50 epochs...\n",
            "Using data config: ./trash-detection/Dataset/data.yaml\n",
            "Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=-1, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=./trash-detection/Dataset/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=YOLOv8n_Run1_DefaultLR2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/detect, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/YOLOv8n_Run1_DefaultLR2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=4\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,628 parameters, 3,011,612 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 861.9Â±265.2 MB/s, size: 39.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/trash-detection/Dataset/labels/augmented_train... 2882 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2882/2882 2.3Kit/s 1.3s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/trash-detection/Dataset/labels/augmented_train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 60.0% CUDA memory utilization.\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla T4) 14.74G total, 0.66G reserved, 0.10G allocated, 13.98G free\n",
            "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
            "     3011628       8.197         1.460         19.69         21.94        (1, 3, 640, 640)                    list\n",
            "     3011628       16.39         1.481         18.54         25.38        (2, 3, 640, 640)                    list\n",
            "     3011628       32.79         1.483         19.63         41.16        (4, 3, 640, 640)                    list\n",
            "     3011628       65.58         1.822         31.56         58.21        (8, 3, 640, 640)                    list\n",
            "     3011628       131.2         2.739         55.21          89.1       (16, 3, 640, 640)                    list\n",
            "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 76 for CUDA:0 8.68G/14.74G (59%) âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 837.0Â±368.6 MB/s, size: 33.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/trash-detection/Dataset/labels/augmented_train.cache... 2882 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2882/2882 2.1Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.1Â±0.1 ms, read: 1150.4Â±1742.8 MB/s, size: 761.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/trash-detection/Dataset/labels/new_val.cache... 92 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 92/92 19.1Kit/s 0.0s\n",
            "Plotting labels to /content/runs/detect/YOLOv8n_Run1_DefaultLR2/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.00059375), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/YOLOv8n_Run1_DefaultLR2\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50      9.73G      1.723       3.26      1.153        679        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.6s/it 2:16\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0s/it 1.0s\n",
            "                   all         92        591    0.00611      0.319      0.176      0.106\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50      10.7G      1.604      1.845      1.094        438        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.8s/it 1:46\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1it/s 0.9s\n",
            "                   all         92        591      0.837     0.0484      0.297      0.174\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50      9.74G      1.572      1.611      1.089        544        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.9s/it 1:51\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.2s/it 1.2s\n",
            "                   all         92        591      0.817      0.343      0.448      0.265\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50        10G      1.547      1.457      1.068        533        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.1s/it 1:59\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1it/s 0.9s\n",
            "                   all         92        591      0.578      0.471      0.485      0.254\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50      10.2G      1.512      1.339      1.063        513        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.7s/it 1:44\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1s/it 1.1s\n",
            "                   all         92        591      0.761      0.445      0.541      0.313\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50      9.12G      1.473      1.245      1.051        495        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.0s/it 1:54\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.5s/it 1.5s\n",
            "                   all         92        591      0.776      0.497      0.604      0.359\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50      9.51G      1.458       1.21      1.046        559        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.9s/it 1:51\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.3s/it 1.3s\n",
            "                   all         92        591      0.828      0.463       0.57      0.312\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50      9.43G      1.437      1.136      1.039        508        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.9s/it 1:49\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.3s/it 1.3s\n",
            "                   all         92        591      0.659      0.599      0.654       0.39\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50      9.14G       1.42      1.113      1.032        503        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.9s/it 1:50\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.5s/it 1.5s\n",
            "                   all         92        591      0.759      0.535      0.659      0.394\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50      10.1G      1.404      1.105      1.026        557        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.0s/it 1:54\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0it/s 1.0s\n",
            "                   all         92        591      0.859      0.502      0.614       0.38\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50      9.87G      1.379      1.071      1.018        514        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.9s/it 1:52\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.2s/it 1.2s\n",
            "                   all         92        591      0.847      0.494      0.643      0.395\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50      9.47G      1.371      1.042      1.018        525        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.0s/it 1:54\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1s/it 1.1s\n",
            "                   all         92        591      0.622      0.647      0.685      0.399\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50      9.76G      1.364      1.039      1.012        533        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.0s/it 1:53\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1s/it 1.1s\n",
            "                   all         92        591      0.703      0.632       0.69      0.413\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50      9.98G      1.313      0.997     0.9963        487        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.8s/it 1:48\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.3s/it 1.3s\n",
            "                   all         92        591      0.645      0.656      0.699      0.429\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50      10.3G      1.332          1      1.005        553        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.0s/it 1:53\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.2s/it 1.2s\n",
            "                   all         92        591      0.681      0.641      0.692      0.419\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50      9.99G      1.315     0.9849     0.9944        533        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.9s/it 1:50\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.2s/it 1.2s\n",
            "                   all         92        591      0.916      0.499      0.698      0.411\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50      9.73G      1.298     0.9629     0.9859        504        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.0s/it 1:55\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.2it/s 0.9s\n",
            "                   all         92        591      0.618      0.669      0.685      0.429\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50        10G      1.294     0.9496     0.9861        442        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.8s/it 1:46\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.4s/it 1.4s\n",
            "                   all         92        591      0.715      0.642      0.694      0.444\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50      10.5G      1.284     0.9554     0.9867        490        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.3s/it 2:04\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0s/it 1.0s\n",
            "                   all         92        591      0.683       0.63      0.685      0.423\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50      10.2G      1.274     0.9223     0.9808        412        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.8s/it 1:47\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0s/it 1.0s\n",
            "                   all         92        591      0.706      0.716      0.742      0.451\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50      9.34G      1.269     0.9293     0.9825        503        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.1s/it 1:57\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1s/it 1.1s\n",
            "                   all         92        591      0.689      0.671      0.725      0.443\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50      9.36G      1.245     0.9065     0.9741        580        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.0s/it 1:53\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1s/it 1.1s\n",
            "                   all         92        591      0.657      0.669      0.719      0.451\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50      9.17G      1.239     0.8963     0.9682        482        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.9s/it 1:51\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1s/it 1.1s\n",
            "                   all         92        591      0.689      0.682      0.717      0.432\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50      9.39G      1.236     0.8881     0.9669        441        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.0s/it 1:55\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.5it/s 0.7s\n",
            "                   all         92        591      0.698      0.735      0.756      0.476\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50      9.53G      1.231     0.8885     0.9679        527        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.8s/it 1:47\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.2s/it 1.2s\n",
            "                   all         92        591       0.66       0.68       0.74      0.465\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/50      10.2G      1.229      0.864     0.9556        492        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.7s/it 1:41\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1s/it 1.1s\n",
            "                   all         92        591       0.66       0.68       0.74       0.46\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/50      9.99G      1.207      0.858      0.961        563        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.9s/it 1:49\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7s/it 1.7s\n",
            "                   all         92        591      0.771      0.715      0.765      0.479\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/50      9.14G      1.202     0.8474     0.9597        505        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.0s/it 1:55\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0s/it 1.0s\n",
            "                   all         92        591      0.689      0.725      0.744      0.462\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/50      10.3G      1.201     0.8516     0.9576        589        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.1s/it 1:56\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5s/it 2.5s\n",
            "                   all         92        591      0.764      0.709      0.757      0.487\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/50      10.3G      1.171     0.8327     0.9491        547        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.8s/it 1:46\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.3s/it 1.3s\n",
            "                   all         92        591      0.712      0.688      0.742      0.478\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/50      9.91G      1.175     0.8278     0.9463        514        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.0s/it 1:53\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.2s/it 1.2s\n",
            "                   all         92        591      0.686       0.74      0.768      0.491\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/50      10.5G      1.165      0.813     0.9428        481        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.9s/it 1:49\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1s/it 1.1s\n",
            "                   all         92        591      0.707      0.718      0.753       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/50      9.73G      1.157     0.8055     0.9412        558        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.9s/it 1:49\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0s/it 1.0s\n",
            "                   all         92        591      0.752      0.686      0.738      0.475\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/50      9.48G      1.158     0.8207     0.9456        643        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.0s/it 1:53\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0it/s 1.0s\n",
            "                   all         92        591      0.707       0.72      0.765      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/50      9.71G      1.147     0.7902     0.9422        527        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.0s/it 1:55\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0s/it 1.0s\n",
            "                   all         92        591      0.725      0.737      0.772        0.5\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/50      9.52G      1.131     0.7847     0.9356        487        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.9s/it 1:49\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0s/it 1.0s\n",
            "                   all         92        591       0.69      0.742      0.774      0.494\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/50      10.5G      1.139      0.788     0.9391        569        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.0s/it 1:55\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.4it/s 0.7s\n",
            "                   all         92        591      0.748       0.73      0.774      0.496\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/50      9.67G      1.118     0.7635     0.9303        507        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.0s/it 1:55\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1s/it 1.1s\n",
            "                   all         92        591      0.708      0.741      0.782      0.501\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/50      9.63G      1.117     0.7738     0.9347        480        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.9s/it 1:52\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1s/it 1.1s\n",
            "                   all         92        591      0.784      0.691      0.772      0.498\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/50      9.58G      1.102     0.7557     0.9299        549        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.9s/it 1:50\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0s/it 1.0s\n",
            "                   all         92        591      0.728      0.747      0.792      0.505\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/50      9.44G       1.08     0.7362       0.92        292        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.0s/it 1:56\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7s/it 1.7s\n",
            "                   all         92        591      0.695      0.729      0.768      0.487\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/50      9.58G       1.06     0.7127     0.9127        340        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.8s/it 1:47\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.3s/it 1.3s\n",
            "                   all         92        591      0.715      0.719      0.758      0.483\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/50      9.74G      1.054     0.6968     0.9112        298        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.0s/it 1:55\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1it/s 0.9s\n",
            "                   all         92        591      0.721      0.761      0.787      0.506\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/50      9.44G      1.039      0.693     0.9046        321        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.0s/it 1:55\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0s/it 1.0s\n",
            "                   all         92        591      0.773       0.75      0.793      0.519\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/50       9.7G      1.036     0.6861     0.9031        286        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.8s/it 1:48\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.2it/s 0.8s\n",
            "                   all         92        591      0.743      0.757      0.794      0.511\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/50      9.26G       1.03     0.6822     0.9084        347        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.8s/it 1:47\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0s/it 1.0s\n",
            "                   all         92        591      0.764      0.751      0.801      0.515\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/50      9.29G      1.014     0.6697     0.8988        282        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.8s/it 1:45\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.4s/it 1.4s\n",
            "                   all         92        591      0.783      0.747      0.801      0.516\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/50      9.46G      1.013     0.6648     0.9022        269        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.9s/it 1:49\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.1s/it 1.1s\n",
            "                   all         92        591      0.763      0.754      0.792      0.513\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/50      9.15G      1.003     0.6574     0.8964        284        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 2.7s/it 1:44\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.2s/it 1.2s\n",
            "                   all         92        591      0.765      0.738      0.797       0.52\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/50      9.65G      1.003     0.6521     0.8982        303        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 38/38 3.0s/it 1:55\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.0s/it 1.0s\n",
            "                   all         92        591      0.775      0.766      0.802      0.518\n",
            "\n",
            "50 epochs completed in 1.598 hours.\n",
            "Optimizer stripped from /content/runs/detect/YOLOv8n_Run1_DefaultLR2/weights/last.pt, 6.3MB\n",
            "Optimizer stripped from /content/runs/detect/YOLOv8n_Run1_DefaultLR2/weights/best.pt, 6.3MB\n",
            "\n",
            "Validating /content/runs/detect/YOLOv8n_Run1_DefaultLR2/weights/best.pt...\n",
            "Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.5s/it 1.5s\n",
            "                   all         92        591      0.761      0.742      0.796      0.519\n",
            "                  dirt         29         99       0.98          1      0.995      0.699\n",
            "                liquid         11         42      0.759      0.929      0.955      0.699\n",
            "                 marks         31        239        0.9      0.573      0.807      0.382\n",
            "                 trash         44        211      0.407      0.464      0.426      0.296\n",
            "Speed: 0.3ms preprocess, 3.0ms inference, 0.0ms loss, 3.6ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/YOLOv8n_Run1_DefaultLR2\u001b[0m\n",
            "Training Run 1 finished successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Model Evaluation on Validation Set\n",
        "Performance Evaluation and Training Run Comparison\n",
        "After completing both runs, we evaluate the performance of the best model (best.pt) from each run on the validation set (the 30% we allocated earlier). The main metric we compare is mAP (Mean Average Precision). This step determines which learning rate was more effective and selects the winning model."
      ],
      "metadata": {
        "id": "ROA1TUNYPdyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Path to the best trained model weights from Run 1.\n",
        "# Note: The actual folder name includes '2' at the end as seen in the training output.\n",
        "model_path = os.path.join(PROJECT_NAME, RUN1_NAME + '2', 'weights', 'best.pt')\n",
        "\n",
        "# Load the best model\n",
        "print(f\"Loading best model from: {model_path}\")\n",
        "loaded_model = YOLO(model_path)\n",
        "\n",
        "# Evaluate the model on the test dataset using the data_config_path and specifying the 'test' split\n",
        "print(\"\\nEvaluating model on the test dataset...\")\n",
        "metrics_test = loaded_model.val(data=data_config_path, split='test')\n",
        "\n",
        "print(\"\\nEvaluation on test dataset completed.\")\n",
        "\n",
        "# Display key metrics from the test set evaluation\n",
        "print(\"--- Test Set Metrics ---\")\n",
        "print(f\"Overall mAP50: {metrics_test.results_dict['metrics/mAP50(B)']:.3f}\")\n",
        "print(f\"Overall mAP50-95: {metrics_test.results_dict['metrics/mAP50-95(B)']:.3f}\")\n",
        "\n",
        "# Display per-class metrics\n",
        "print(\"\\nPer-Class Metrics:\")\n",
        "for i, class_name in enumerate(metrics_test.names):\n",
        "    # Direct access to per-class metrics. These attributes (p, r, map) are expected to be arrays\n",
        "    # of length equal to the number of classes.\n",
        "    p = metrics_test.box.p[i]\n",
        "    r = metrics_test.box.r[i]\n",
        "    map50 = metrics_test.box.map[i]\n",
        "    print(f\"  Class '{class_name}' (ID {i}) - Precision: {p:.3f}, Recall: {r:.3f}, mAP50: {map50:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "JVO9hwUxQ0YP",
        "outputId": "e595ca2c-ae8a-47b1-f879-dab6b671b1f7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading best model from: runs/detect/YOLOv8n_Run1_DefaultLR2/weights/best.pt\n",
            "\n",
            "Evaluating model on the test dataset...\n",
            "Ultralytics 8.3.233 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1190.5Â±788.9 MB/s, size: 235.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/trash-detection/Dataset/labels/test.cache... 216 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 216/216 334.7Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.1it/s 12.8s\n",
            "                   all        216       1427      0.757      0.754      0.788       0.52\n",
            "                  dirt         74        268      0.961      0.996      0.995      0.737\n",
            "                liquid         29         98      0.788       0.98      0.979      0.714\n",
            "                 marks         88        583        0.9      0.652      0.835      0.397\n",
            "                 trash        101        478      0.376      0.389      0.343      0.232\n",
            "Speed: 4.3ms preprocess, 4.4ms inference, 0.0ms loss, 2.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val3\u001b[0m\n",
            "\n",
            "Evaluation on test dataset completed.\n",
            "--- Test Set Metrics ---\n",
            "Overall mAP50: 0.788\n",
            "Overall mAP50-95: 0.520\n",
            "\n",
            "Per-Class Metrics:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "invalid index to scalar variable.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2798552606.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmap50\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  Class '{class_name}' (ID {i}) - Precision: {p:.3f}, Recall: {r:.3f}, mAP50: {map50:.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
          ]
        }
      ]
    }
  ]
}